{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lowcarb Tutorial\n",
    "\n",
    "Enabling **privacy-aware** and **carbon-aware** machine learning. Powered by the [Carbon-Aware-SDK](https://github.com/Green-Software-Foundation/carbon-aware-sdk).\n",
    "\n",
    "This notebook follows along the official [Introduction to Federated Learning](https://flower.dev/docs/tutorial/Flower-1-Intro-to-FL-PyTorch.html) from the Flower using PyTorch and the CIFAR-10 dataset.\n",
    "\n",
    "The **two** extra steps to make your Flower application carbon aware are highlighted along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "\n",
    "from random import sample\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 20\n",
    "BATCH_SIZE = 32\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(num_clients=NUM_CLIENTS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the Neural Net\n",
    "...using the CIFAR10 dataset. For an in-depth explanation see the [Flower tutorial](https://flower.dev/docs/tutorial/Flower-1-Intro-to-FL-PyTorch.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "def weighted_average(metrics):\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing Lowcarb Flower Clients\n",
    "The `FlowerClient` for this demo is based on the [Flower tutorial](https://flower.dev/docs/tutorial/Flower-1-Intro-to-FL-PyTorch.html).\n",
    "\n",
    "To make your client implementation compatible with lowcarb's `LowcarbClientManager` (which we'll meet further down the line), you only have to make sure its `get_properties()` returns a dict containing the client's `location` as a `str`, e.g. *'uksouth'*, *'westeurope'*, *'westus'*, ...\n",
    "\n",
    "Note: If your client's location changes throughout its lifetime, just update it dynamically in `get_properties()`. The `LowcarbClientManager` queries it each round."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader, location: str, *args, **kwargs):\n",
    "        super(FlowerClient, self).__init__(*args, **kwargs)\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "        ### Giving the client a location upon instantiation\n",
    "        self.location = location\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "    # Make sure the get_properties() method returns the client's location\n",
    "    def get_properties(self, config) -> dict:\n",
    "        return {'location': self.location}\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial, we simulate a federated learning training using flower's integrated simulation capabilities, so we need to implement a client generator."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_regions = ['westcentralus', 'ukwest', 'uksouth', 'westeurope', 'westus', 'australiacentral', 'australiaeast', 'swedencentral', 'norwaywest', 'norwayeast', 'northeurope', 'centralus', 'francesouth', 'francecentral']\n",
    "client_regions_by_cid = [sample(available_regions, 1)[0] for i in range(0, NUM_CLIENTS)]\n",
    "\n",
    "def client_generator(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(net, trainloader, valloader, location=client_regions_by_cid[int(cid)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LowcarbClientManager` is powered by the [Carbon-Aware-SDK](https://github.com/Green-Software-Foundation/carbon-aware-sdk). Feel free to host it locally or use a remote endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from lowcarb import LowcarbClientManager\n",
    "\n",
    "CARBON_AWARE_SDK_HOST = 'https://carbon-aware-api.azurewebsites.net'\n",
    "lowcarb_client_manager = LowcarbClientManager(api_host=CARBON_AWARE_SDK_HOST, workload_duration=15, forecast_window=12)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-11-02 18:57:50,627 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "INFO flower 2022-11-02 18:57:57,434 | app.py:176 | Flower VCE: Ray initialized with resources: {'object_store_memory': 2147483648.0, 'node:127.0.0.1': 1.0, 'memory': 19900447130.0, 'CPU': 8.0}\n",
      "INFO flower 2022-11-02 18:57:57,436 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-11-02 18:57:57,436 | server.py:270 | Requesting initial parameters from one random client\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [15], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Start simulation\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mfl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_simulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_clients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mNUM_CLIENTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mServerConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# strategy=strategy,\u001B[39;49;00m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlowcarb_client_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pass the lowcarb_client_manager to the simulation\u001B[39;49;00m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Dev/carbonhack22/venv/lib/python3.8/site-packages/flwr/simulation/app.py:193\u001B[0m, in \u001B[0;36mstart_simulation\u001B[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001B[0m\n\u001B[1;32m    190\u001B[0m     initialized_server\u001B[38;5;241m.\u001B[39mclient_manager()\u001B[38;5;241m.\u001B[39mregister(client\u001B[38;5;241m=\u001B[39mclient_proxy)\n\u001B[1;32m    192\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[0;32m--> 193\u001B[0m hist \u001B[38;5;241m=\u001B[39m \u001B[43m_fl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitialized_server\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitialized_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hist\n",
      "File \u001B[0;32m~/Dev/carbonhack22/venv/lib/python3.8/site-packages/flwr/server/app.py:179\u001B[0m, in \u001B[0;36m_fl\u001B[0;34m(server, config)\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_fl\u001B[39m(\n\u001B[1;32m    175\u001B[0m     server: Server,\n\u001B[1;32m    176\u001B[0m     config: ServerConfig,\n\u001B[1;32m    177\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m History:\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;66;03m# Fit model\u001B[39;00m\n\u001B[0;32m--> 179\u001B[0m     hist \u001B[38;5;241m=\u001B[39m \u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_rounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mround_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m     log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapp_fit: losses_distributed \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mstr\u001B[39m(hist\u001B[38;5;241m.\u001B[39mlosses_distributed))\n\u001B[1;32m    181\u001B[0m     log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapp_fit: metrics_distributed \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mstr\u001B[39m(hist\u001B[38;5;241m.\u001B[39mmetrics_distributed))\n",
      "File \u001B[0;32m~/Dev/carbonhack22/venv/lib/python3.8/site-packages/flwr/server/server.py:87\u001B[0m, in \u001B[0;36mServer.fit\u001B[0;34m(self, num_rounds, timeout)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;66;03m# Initialize parameters\u001B[39;00m\n\u001B[1;32m     86\u001B[0m log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitializing global parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 87\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_initial_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating initial parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     89\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mevaluate(\u001B[38;5;241m0\u001B[39m, parameters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters)\n",
      "File \u001B[0;32m~/Dev/carbonhack22/venv/lib/python3.8/site-packages/flwr/server/server.py:271\u001B[0m, in \u001B[0;36mServer._get_initial_parameters\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;66;03m# Get initial parameters from one of the clients\u001B[39;00m\n\u001B[1;32m    270\u001B[0m log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequesting initial parameters from one random client\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 271\u001B[0m random_client \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    272\u001B[0m ins \u001B[38;5;241m=\u001B[39m GetParametersIns(config\u001B[38;5;241m=\u001B[39m{})\n\u001B[1;32m    273\u001B[0m get_parameters_res \u001B[38;5;241m=\u001B[39m random_client\u001B[38;5;241m.\u001B[39mget_parameters(ins\u001B[38;5;241m=\u001B[39mins, timeout\u001B[38;5;241m=\u001B[39mtimeout)\n",
      "File \u001B[0;32m~/Dev/carbonhack22/lowcarb/_client_manager.py:50\u001B[0m, in \u001B[0;36mLowcarbClientManager.sample\u001B[0;34m(self, num_clients, min_num_clients, criterion)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m criterion \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     47\u001B[0m     available_cids \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     48\u001B[0m         cid \u001B[38;5;28;01mfor\u001B[39;00m cid \u001B[38;5;129;01min\u001B[39;00m available_cids \u001B[38;5;28;01mif\u001B[39;00m criterion\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclients[cid])\n\u001B[1;32m     49\u001B[0m     ]\n\u001B[0;32m---> 50\u001B[0m sampled_cids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mavailable_cids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_clients\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclients[cid] \u001B[38;5;28;01mfor\u001B[39;00m cid \u001B[38;5;129;01min\u001B[39;00m sampled_cids]\n",
      "File \u001B[0;32m~/Dev/carbonhack22/lowcarb/_client_manager.py:56\u001B[0m, in \u001B[0;36mLowcarbClientManager._sample\u001B[0;34m(self, available_cids, num_clients)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;124;03m\"\"\"Carbon-aware client selection strategy.\"\"\"\u001B[39;00m\n\u001B[1;32m     55\u001B[0m client_location_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_client_locations()\n\u001B[0;32m---> 56\u001B[0m carbon_forecasts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_carbon_forecasts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mclient_location_map\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m available_cids_participation \u001B[38;5;241m=\u001B[39m {cid: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient_participation[cid] \u001B[38;5;28;01mfor\u001B[39;00m cid \u001B[38;5;129;01min\u001B[39;00m available_cids}\n\u001B[1;32m     59\u001B[0m strategy \u001B[38;5;241m=\u001B[39m CarbonAwareStrategy(num_clients\u001B[38;5;241m=\u001B[39mnum_clients, max_forecast_duration\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforecast_window)\n",
      "File \u001B[0;32m~/Dev/carbonhack22/lowcarb/_client_manager.py:82\u001B[0m, in \u001B[0;36mLowcarbClientManager._get_carbon_forecasts\u001B[0;34m(self, locations)\u001B[0m\n\u001B[1;32m     78\u001B[0m     end \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow() \u001B[38;5;241m+\u001B[39m timedelta(hours\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforecast_window)\n\u001B[1;32m     79\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_instance\u001B[38;5;241m.\u001B[39mget_current_forecast_data([location],\n\u001B[1;32m     80\u001B[0m                                                            data_end_at\u001B[38;5;241m=\u001B[39mend,\n\u001B[1;32m     81\u001B[0m                                                            window_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforecast_window)\n\u001B[0;32m---> 82\u001B[0m     dfs\u001B[38;5;241m.\u001B[39mappend(\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtime\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mentry\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtimestamp\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mentry\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforecast_data\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvalue\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mentry\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvalue\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mentry\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforecast_data\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlocation\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocations\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     87\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(dfs)\n\u001B[1;32m     88\u001B[0m forecasts \u001B[38;5;241m=\u001B[39m {region: forecast[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto_list() \u001B[38;5;28;01mfor\u001B[39;00m region, forecast \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregion\u001B[39m\u001B[38;5;124m'\u001B[39m)}\n",
      "File \u001B[0;32m~/Dev/carbonhack22/venv/lib/python3.8/site-packages/pandas/core/frame.py:662\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    656\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_mgr(\n\u001B[1;32m    657\u001B[0m         data, axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: columns}, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[1;32m    658\u001B[0m     )\n\u001B[1;32m    660\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    661\u001B[0m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[0;32m--> 662\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    663\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma\u001B[38;5;241m.\u001B[39mMaskedArray):\n\u001B[1;32m    664\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mma\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmrecords\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmrecords\u001B[39;00m\n",
      "File \u001B[0;32m~/Dev/carbonhack22/venv/lib/python3.8/site-packages/pandas/core/internals/construction.py:493\u001B[0m, in \u001B[0;36mdict_to_mgr\u001B[0;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[1;32m    489\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    490\u001B[0m         \u001B[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001B[39;00m\n\u001B[1;32m    491\u001B[0m         arrays \u001B[38;5;241m=\u001B[39m [x\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[0;32m--> 493\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Dev/carbonhack22/venv/lib/python3.8/site-packages/pandas/core/internals/construction.py:118\u001B[0m, in \u001B[0;36marrays_to_mgr\u001B[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verify_integrity:\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;66;03m# figure out the index, if necessary\u001B[39;00m\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 118\u001B[0m         index \u001B[38;5;241m=\u001B[39m \u001B[43m_extract_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    120\u001B[0m         index \u001B[38;5;241m=\u001B[39m ensure_index(index)\n",
      "File \u001B[0;32m~/Dev/carbonhack22/venv/lib/python3.8/site-packages/pandas/core/internals/construction.py:666\u001B[0m, in \u001B[0;36m_extract_index\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    664\u001B[0m lengths \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mset\u001B[39m(raw_lengths))\n\u001B[1;32m    665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(lengths) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 666\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll arrays must be of the same length\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    668\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m have_dicts:\n\u001B[1;32m    669\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    670\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    671\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_generator,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    client_manager=lowcarb_client_manager,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}