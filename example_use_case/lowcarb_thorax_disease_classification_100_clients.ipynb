{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLU2v46A66u2"
      },
      "source": [
        "# LowCarb thorax disease classification in Flower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHtLCCz2NWC3"
      },
      "source": [
        "## Check GPU availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mKwZQyyLwUv",
        "outputId": "7e641d7b-12d0-47ce-ef5c-e78fc94a7750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 21 14:33:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   28C    P0    46W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtoyp-b2NYIe"
      },
      "source": [
        "## Create dirs, get data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7fODONtR3CgP"
      },
      "outputs": [],
      "source": [
        "# !mkdir NIH\n",
        "# !mkdir /root/.kaggle/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmJd_Jb62xQt"
      },
      "source": [
        "### Copy Kaggle API-key to created directory at '/root/.kaggle'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vgDZ9Zbqmn9E"
      },
      "outputs": [],
      "source": [
        "# !cp '/content/drive/MyDrive/professional/Research_Jobs/UMI/projects/APIs/kaggle.json' '/root/.kaggle'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZWLdG0c35F5v"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d nih-chest-xrays/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q9vB9RBo3GWB"
      },
      "outputs": [],
      "source": [
        "# !unzip -q '/content/data.zip' -d '/content/NIH/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CowQiKO63e8"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lHXOfCIZ6vey",
        "outputId": "18d527b1-d1a3-4082-8036-a1d1f6818f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flwr[simulation]\n",
            "  Downloading flwr-1.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting protobuf<4.0.0,>=3.19.0\n",
            "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]) (4.13.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]) (1.21.6)\n",
            "Collecting iterators<0.0.3,>=0.0.2\n",
            "  Downloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.43.0 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]) (1.49.1)\n",
            "Collecting ray[default]<1.14.0,>=1.13.0\n",
            "  Downloading ray-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl (54.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.5 MB 116.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<2.0.0,>=1.43.0->flwr[simulation]) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0,>=4.0.0->flwr[simulation]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0,>=4.0.0->flwr[simulation]) (3.9.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (1.3.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (1.0.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (4.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (3.8.0)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.16.5-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (2.23.0)\n",
            "Collecting grpcio<2.0.0,>=1.43.0\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 11 kB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (22.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (6.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (7.1.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (1.2.0)\n",
            "Collecting prometheus-client<0.14.0,>=0.7.1\n",
            "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (5.2.1)\n",
            "Collecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 86.0 MB/s \n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 74.3 MB/s \n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0.tar.gz (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 12.0 MB/s \n",
            "\u001b[?25hCollecting opencensus\n",
            "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 80.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.7/dist-packages (from ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (3.8.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (2.1.1)\n",
            "Collecting nvidia-ml-py<=11.495.46,>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
            "Collecting psutil>=5.6.0\n",
            "  Downloading psutil-5.9.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "\u001b[K     |████████████████████████████████| 291 kB 87.3 MB/s \n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (0.2.5)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp>=3.7->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (2.10)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (5.10.0)\n",
            "Collecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (1.31.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (2022.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (1.56.4)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]<1.14.0,>=1.13.0->flwr[simulation]) (3.0.4)\n",
            "Collecting platformdirs<3,>=2.4\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.5\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 84.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0-py3-none-any.whl size=19889 sha256=1b2b928b78007f58b4cdbff88bd974d5eb844e68de2bdf9ff556af69bd112198\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/31/5c/eb69af6e2285e7d6ec8d7dc26435be7c81c6ad22c45efdcca7\n",
            "Successfully built gpustat\n",
            "Installing collected packages: protobuf, platformdirs, distlib, virtualenv, psutil, opencensus-context, nvidia-ml-py, grpcio, blessed, ray, py-spy, prometheus-client, opencensus, iterators, gpustat, colorful, aiohttp-cors, flwr\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.49.1\n",
            "    Uninstalling grpcio-1.49.1:\n",
            "      Successfully uninstalled grpcio-1.49.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-cors-0.7.0 blessed-1.19.1 colorful-0.5.4 distlib-0.3.6 flwr-1.0.0 gpustat-1.0.0 grpcio-1.43.0 iterators-0.0.2 nvidia-ml-py-11.495.46 opencensus-0.11.0 opencensus-context-0.1.3 platformdirs-2.5.2 prometheus-client-0.13.1 protobuf-3.20.3 psutil-5.9.3 py-spy-0.3.14 ray-1.13.0 virtualenv-20.16.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install flwr[simulation]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grNc2GELvjD3"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHQ-3tCTvlPv",
        "outputId": "6bb8d7d0-b613-464c-a341-e9b9d31268a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda:0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nnqunt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms as T, models\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5XXXYdm6ic5"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45ozbtM24s2k"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Yz34zjmYPihV"
      },
      "outputs": [],
      "source": [
        "root_img_dir = '/content/NIH/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "OPOdXKySPN2-",
        "outputId": "3988d3a2-2a2b-4480-c726-02ee1b52c6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scans found: 112120 , Total Headers 112120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Image Index             Finding Labels  Follow-up #  Patient ID  \\\n",
              "27969  00007287_000.png                 No Finding            0        7287   \n",
              "35975  00009490_000.png      Effusion|Infiltration            0        9490   \n",
              "3311   00000877_005.png  Atelectasis|Consolidation            5         877   \n",
              "\n",
              "       Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
              "27969           45              F            PA                 2048     2500   \n",
              "35975           29              F            PA                 2048     2500   \n",
              "3311            35              M            AP                 2500     2048   \n",
              "\n",
              "       OriginalImagePixelSpacing[x     y]  Unnamed: 11  \\\n",
              "27969                        0.168  0.168          NaN   \n",
              "35975                        0.168  0.168          NaN   \n",
              "3311                         0.168  0.168          NaN   \n",
              "\n",
              "                                                  path  \n",
              "27969  /content/NIH/images_004/images/00007287_000.png  \n",
              "35975  /content/NIH/images_005/images/00009490_000.png  \n",
              "3311   /content/NIH/images_001/images/00000877_005.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6dee3b4c-52ce-49c2-b9f0-c37c2e2dbdb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "      <th>Follow-up #</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Gender</th>\n",
              "      <th>View Position</th>\n",
              "      <th>OriginalImage[Width</th>\n",
              "      <th>Height]</th>\n",
              "      <th>OriginalImagePixelSpacing[x</th>\n",
              "      <th>y]</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27969</th>\n",
              "      <td>00007287_000.png</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>0</td>\n",
              "      <td>7287</td>\n",
              "      <td>45</td>\n",
              "      <td>F</td>\n",
              "      <td>PA</td>\n",
              "      <td>2048</td>\n",
              "      <td>2500</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/NIH/images_004/images/00007287_000.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35975</th>\n",
              "      <td>00009490_000.png</td>\n",
              "      <td>Effusion|Infiltration</td>\n",
              "      <td>0</td>\n",
              "      <td>9490</td>\n",
              "      <td>29</td>\n",
              "      <td>F</td>\n",
              "      <td>PA</td>\n",
              "      <td>2048</td>\n",
              "      <td>2500</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/NIH/images_005/images/00009490_000.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3311</th>\n",
              "      <td>00000877_005.png</td>\n",
              "      <td>Atelectasis|Consolidation</td>\n",
              "      <td>5</td>\n",
              "      <td>877</td>\n",
              "      <td>35</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/NIH/images_001/images/00000877_005.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6dee3b4c-52ce-49c2-b9f0-c37c2e2dbdb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6dee3b4c-52ce-49c2-b9f0-c37c2e2dbdb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6dee3b4c-52ce-49c2-b9f0-c37c2e2dbdb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "all_xray_df = pd.read_csv(\n",
        "    os.path.join(\n",
        "        root_img_dir,\n",
        "        'Data_Entry_2017.csv'\n",
        "        )\n",
        "    )\n",
        "\n",
        "all_image_paths = {\n",
        "    os.path.basename(x): x for x in \n",
        "    glob(os.path.join(root_img_dir, 'images*', '*', '*.png'))\n",
        "    }\n",
        "\n",
        "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
        "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
        "# all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\n",
        "\n",
        "all_xray_df.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "w6zolca4PN5x",
        "outputId": "361921e7-71b0-4eb3-f0f3-f5960ed4232c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\n",
        "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
        "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
        "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
        "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "us8ftKY8PN8b",
        "outputId": "c7f0c5fa-b43c-47c8-c119-cc7226150a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Labels (14): ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Image Index         Finding Labels  Follow-up #  Patient ID  \\\n",
              "5664   00001527_000.png     Pleural_Thickening            0        1527   \n",
              "96040  00025261_002.png  Effusion|Infiltration            2       25261   \n",
              "56178  00014006_004.png           Infiltration            4       14006   \n",
              "\n",
              "       Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
              "5664            62              F            PA                 2992     2991   \n",
              "96040           58              F            PA                 2642     2991   \n",
              "56178           45              M            PA                 2992     2991   \n",
              "\n",
              "       OriginalImagePixelSpacing[x  ...  Effusion  Emphysema Fibrosis  Hernia  \\\n",
              "5664                         0.143  ...       0.0        0.0      0.0     0.0   \n",
              "96040                        0.143  ...       1.0        0.0      0.0     0.0   \n",
              "56178                        0.143  ...       0.0        0.0      0.0     0.0   \n",
              "\n",
              "       Infiltration  Mass  Nodule  Pleural_Thickening  Pneumonia  Pneumothorax  \n",
              "5664            0.0   0.0     0.0                 1.0        0.0           0.0  \n",
              "96040           1.0   0.0     0.0                 0.0        0.0           0.0  \n",
              "56178           1.0   0.0     0.0                 0.0        0.0           0.0  \n",
              "\n",
              "[3 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4995ae37-93c6-4aca-9abf-0161880495b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "      <th>Follow-up #</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Gender</th>\n",
              "      <th>View Position</th>\n",
              "      <th>OriginalImage[Width</th>\n",
              "      <th>Height]</th>\n",
              "      <th>OriginalImagePixelSpacing[x</th>\n",
              "      <th>...</th>\n",
              "      <th>Effusion</th>\n",
              "      <th>Emphysema</th>\n",
              "      <th>Fibrosis</th>\n",
              "      <th>Hernia</th>\n",
              "      <th>Infiltration</th>\n",
              "      <th>Mass</th>\n",
              "      <th>Nodule</th>\n",
              "      <th>Pleural_Thickening</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Pneumothorax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5664</th>\n",
              "      <td>00001527_000.png</td>\n",
              "      <td>Pleural_Thickening</td>\n",
              "      <td>0</td>\n",
              "      <td>1527</td>\n",
              "      <td>62</td>\n",
              "      <td>F</td>\n",
              "      <td>PA</td>\n",
              "      <td>2992</td>\n",
              "      <td>2991</td>\n",
              "      <td>0.143</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96040</th>\n",
              "      <td>00025261_002.png</td>\n",
              "      <td>Effusion|Infiltration</td>\n",
              "      <td>2</td>\n",
              "      <td>25261</td>\n",
              "      <td>58</td>\n",
              "      <td>F</td>\n",
              "      <td>PA</td>\n",
              "      <td>2642</td>\n",
              "      <td>2991</td>\n",
              "      <td>0.143</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56178</th>\n",
              "      <td>00014006_004.png</td>\n",
              "      <td>Infiltration</td>\n",
              "      <td>4</td>\n",
              "      <td>14006</td>\n",
              "      <td>45</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2992</td>\n",
              "      <td>2991</td>\n",
              "      <td>0.143</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4995ae37-93c6-4aca-9abf-0161880495b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4995ae37-93c6-4aca-9abf-0161880495b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4995ae37-93c6-4aca-9abf-0161880495b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
        "from itertools import chain\n",
        "all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
        "all_labels = [x for x in all_labels if len(x)>0]\n",
        "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
        "for c_label in all_labels:\n",
        "    if len(c_label)>1: # leave out empty labels\n",
        "        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
        "all_xray_df.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym5CxJBDTuQZ",
        "outputId": "3a941ab0-8419-4687-8118-4fe1e80485df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean Labels (13) [('Atelectasis', 11559), ('Cardiomegaly', 2776), ('Consolidation', 4667), ('Edema', 2303), ('Effusion', 13317), ('Emphysema', 2516), ('Fibrosis', 1686), ('Infiltration', 19894), ('Mass', 5782), ('Nodule', 6331), ('Pleural_Thickening', 3385), ('Pneumonia', 1431), ('Pneumothorax', 5302)]\n"
          ]
        }
      ],
      "source": [
        "# keep at least 1000 cases\n",
        "MIN_CASES = 1000\n",
        "all_labels = [\n",
        "    c_label for c_label in all_labels if all_xray_df[c_label].sum()>MIN_CASES\n",
        "    ]\n",
        "print('Clean Labels ({})'.format(len(all_labels)), \n",
        "      [(c_label,int(all_xray_df[c_label].sum())) for c_label in all_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "-bMuE8iDT2LT",
        "outputId": "49e07645-bc66-4699-b9ea-7bd805bcb888"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n",
        "# weight is 0.1 + number of findings\n",
        "sample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\n",
        "sample_weights /= sample_weights.sum()\n",
        "\n",
        "all_xray_df = all_xray_df.sample(112120, weights=sample_weights)\n",
        "\n",
        "label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\n",
        "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
        "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
        "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
        "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "T1zRuIqHT5pF",
        "outputId": "fdcc8582-c85b-4964-f930-fc3e2096df04"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAI2CAYAAACblqR6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZglZX33//eHRVBAURlR1nFBFI0gGVF/4hM0gghuMXFB3FE00Z+aaCIuQRSTB3eNuKGCioI7ioIKruCCOCAIboEgRkABQXaU7fv8UdVyaLp7Ts/U6eqaeb+uq68+tZzT31N9qvtTd911V6oKSZIkSaturb4LkCRJklYXhmtJkiSpI4ZrSZIkqSOGa0mSJKkjhmtJkiSpI4ZrSZIkqSOGa2kNkuSjSd7UPn54kl8tgpoOSPKJvusYsiT/mOTCJFclufNKvsbPkuzScWkLZhF9nl+T5MN91yGpP4ZraTWQ5DtJ/phkvXGfU1UnVtW2Hfzsc5M8alVfZ5bX3iXJTW1onPr68iR+1lAlWRd4B7BbVW1YVZdMW740SY1svwuTfCXJrqPrVdX9quo7C1h6p1bl85zkOUlubLfPFUlOS/LYMZ63S5LzptXxn1X1/JWpY9prT/3e1lnBetsk+VSSi9vaz0ryniRbrGoNklaO4VoauCRLgYcDBTy+12Im44I2NE59PW76CisKIKu5TYH1gZ+tYL2Nq2pDYHvgeOCoJM+ZcG1D8sN2+2wMfAT4TJI79lzTnJLcC/gRcAHwwKq6PfAw4H+AnWd5zpq8r0gLwnAtDd+zgJOAjwLPHl2Q5IFJTk1yZZJP04SwqWW3aHVrW8nuNTI92oVkk7a187IklyY5MclaSQ4HtgK+3Lb6/Vu7/kOS/KBd//TR7gZJ7p7ku21NxwObzPcNty2N30/yziSXAAckWS/J25L8b9s6+4Ektx15zr8m+V2SC5I8b/T9ti3/z5/2+t8bmb5PkuPb9/6rJE+Ztp3em+SY9j39KMk9R5bfb+S5F7bdBu6a5JrRLhxJdmxbH9ed4f2ul+Rdbe0XtI/XS3JvYKorxGVJvrWibVdVv6+qdwMHAG9Oslb7M/5yBiLJTkmWty2hFyZ5x0gtc/1un5vkF+12OCfJC0eWzfgZapdtluTz7fv/dZKXjjxv1lqmbaPpn+dzk7wyyU+TXJ7k00nWn+m507bPTcChwG2Be872npJsAHwV2Cw3nxXYLNO6Oa1ge30nyYHtZ/nKJMclmdofTmi/X9a+9kNnKPcA4PtV9S9VdV5b/0VV9a6q+tTodknyqiS/Bw6b7fPUrn+Lz347b3Rf+Wi7bx3f1vzdJFuvaLtKaxLDtTR8zwI+2X49OsmmAEluA3wROBy4E/BZ4O9X8me8AjgPWELTUvoaoKrqmcD/Ao9rW5XfkmRz4BjgTe3PfSXw+SRL2tc6AjiFJlQfyLQDgnl4MHBOW89/AAcB9wZ2AO4FbA7sD5Bk97aOXYFtgLG7sbQh6vi27rsATwPel2S7kdWeBrwBuCNwdlsPSTYCvgF8DdisreubVfV74DvAU0Ze45nAp6rq+hnKeC3wkPa9bQ/sBLyuqv4buF+7zsZV9chx3xfwhfb9zNSV4t3Au9uW0HsCn2nfz4p+txcBjwVuDzwXeGeSHdtlM36G2oD9ZeB0mt/Z3wIvT/LouWoZ01OA3YG7Aw8AnrOiJ6Rp2X0+cBVw1mzvqaquBh7DLc+sXDDttVa0vQCe3r7uXYDbtOsA/J/2+8bta/9whnIfBXx+Re8JuGv787cG9mWWz9MYrzNlb5p9dxPgNJq/PZJahmtpwJLsTPMP8zNVdQrN6eCnt4sfAqwLvKuqrq+qzwE/XskfdT1wN2Dr9rVOrKqaZd1nAMdW1bFVdVNVHQ8sB/ZIshXwIODfq+rPVXUCTbCay2Ztq9/U11QgvaCq3lNVNwB/ogkN/1xVl1bVlcB/0oReaELWYVV1ZhuKDpjHe38scG5VHVZVN1TVT2gCzZNH1jmqqk5ua/kkTWiZeu7vq+rtVfWnqrqyqn7ULvtYu61IsjawF82B0Ez2Bt7YtkpeTBPknzmP9zCTqSB4pxmWXQ/cK8kmVXVVVZ3Uzp/1dwtQVcdU1f9U47vAcTRdlqZec6bP0IOAJVX1xqq6rqrOAT7Ezb+72WoZx39V1QVVdSnN52yHOdZ9SJLLgN/T/C7+rqouX8F7WpE5t1frsKr676q6lubAYa4ap9ukrReAJC9p95GrknxoZL2bgNe3+9y1rPrn6ZiqOqGq/kwT1B+aZMt5PF9arRmupWF7NnBcVf2hnT6Cm1uCNwPOnxaCf7OSP+etNC2yx7WnxvebY92tgSePBmKa/p93a2v6Yxtwx63pgqraeORrquXytyPrLAFuB5wy8jO/1s6n/bmj689nO2wNPHja+9mbpjVwyu9HHl8DbNg+3pLmgGcmXwK2S3J3mhb1y6vq5FnW3Wxazb9p562Kzdvvl86wbB+aswC/TPLj3Hxx31y/W5I8JslJbbePy2hC5FQ3h9k+Q1sz7QCKplV70xXUMo7Zfi8zOan9fG1SVQ+pqm+M8Z5WZM7ttRI1TnfJ6GtV1cFVtTHwLpoD6ykXV9WfRqZX9fP0l32pqq6i+Qyt6udRWm14YYM0UGn6Ez8FWLvtSwmwHrBxku2B3wGbJ8lIwN6K2cPeNTQBdcpdaU7j07YEvwJ4RZL7A99K8uOq+ibNhZSjfgscXlUvmKHmrYE7JtlgJGBvNcNrjGP0OX8ArgXuV1Xnz7Du72iC7pStpi2/mlu/9ym/Bb5bVbsyf7/l5hbYW6iqPyX5DE3r5n2YvdUamlbmrbn5osWtuLnleWX9HU2Xh1sNX1dVZwF7tV02ngR8Lk3/8Ll+t+vRtOg/C/hSVV2f5ItA2tec8TPUvuavq2qbmYqcrZZpB2gTsaL3xIo/t7NurzGMs098k2abHDbP15rr83SLfSHJXbm1LUeWb0hz9mNVP4/SasOWa2m4ngjcCGxHcyp5B+C+wIk0YeCHwA3AS5Osm+RJNH0rZ3Ma8PQka7d9lP9makGSxya5V5IAl7c/96Z28YXAPUZe5xPA45I8un2t9duLqraoqt/QnBZ/Q5LbtN1abjX6x3xVcxHah2j6w96lrXnzkX67nwGek2S7JLcDXj/De39Sktu1F27tM7LsK8C9kzyz3Y7rJnlQkvuOUdpXgLsleXmai8g2SvLgkeUfp+kH/HjmDtdHAq9LsiTNBW/702zneUuyaZKX0GyDV7fbbvo6z0iypF12WTv7Jub43dL0F14PuBi4IcljgN1GXnO2z9DJwJVpLri7bfu690/yoBXUshDmfE80n/07J7nDLM+fa3utyMU07/Mec6xzAPDwJO9I07+b9vOxos/mXJ+n04H7JdkhzQWgB8zw/D2S7Jzmuo4DaVr9fzvDetIayXAtDdezafpr/m81I0D8vpoL5Q6m6bZwE02r1nNoTts+leYittm8jCboTnV7+OLIsm1oLsy7iia0v6+qvt0u+780/6gvS/LK9p/sE2hO7V9M03r3r9z89+bpNBcjXkoT8D6+0lvgll5F0+3gpCRXtPVuC1BVX6U5Vf6tdp3po2q8E7iOJix9jJELtNoW191oWqAvoDmN/2aa0DWn9rm70mzX39NcIPeIkeXfp/k9ndoeeMzmTTQHJT8FzgBObefNx2VJrm6fvwfw5Ko6dJZ1dwd+luQqmgsKn1ZV1871u23f60tpDmT+SPN7PnrkNWf8DFXVjTR903cAfk1zFuLDwFRgnbGWeb73lbKi91RVv6QJque0n//Npj1/RfvCXD/7GpoLY7/fvvZDZljnv2n2pS2A05NcCXyf5nP673O8/Kyfp/Y130jzuzoL+N4Mzz+CZt+9FPhr2msHJDVSs16TJGl1luSRwIeraq6WsdVWkgK2qaqze67jW8ARVeVd/bToJfkocF5VzWd0EWmNYp9rac11f5qWQvWk7fqwI03rpiRpNWC4ltZASd5N0893ZceY1ipK8jGafvMva7sfSJJWA3YLkSRJkjriBY2SJElSRwzXkiRJUkdWqz7Xm2yySS1durTvMiRJkrQaO+WUU/5QVUtmWrZaheulS5eyfPnyvsuQJEnSaizJrPcmsFuIJEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1JF1+i5AkrRmWbrfMX2XMKNzD9qz7xIkrQZsuZYkSZI6MrGW6ySHAo8FLqqq+7fzPg1s266yMXBZVe0ww3PPBa4EbgRuqKplk6pTkiRJ6soku4V8FDgY+PjUjKp66tTjJG8HLp/j+Y+oqj9MrDpJkiSpYxML11V1QpKlMy1LEuApwCMn9fMlSZKkhdZXn+uHAxdW1VmzLC/guCSnJNl3AeuSJEmSVlpfo4XsBRw5x/Kdq+r8JHcBjk/yy6o6YaYV2/C9L8BWW23VfaWSJEnSmBa85TrJOsCTgE/Ptk5Vnd9+vwg4CthpjnUPqaplVbVsyZIlXZcrSZIkja2PbiGPAn5ZVefNtDDJBkk2mnoM7AacuYD1SZIkSStlYuE6yZHAD4Ftk5yXZJ920dOY1iUkyWZJjm0nNwW+l+R04GTgmKr62qTqlCRJkroyydFC9ppl/nNmmHcBsEf7+Bxg+0nVJUmSJE2Kd2iUJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOjKxcJ3k0CQXJTlzZN4BSc5Pclr7tccsz909ya+SnJ1kv0nVKEmSJHVpki3XHwV2n2H+O6tqh/br2OkLk6wNvBd4DLAdsFeS7SZYpyRJktSJiYXrqjoBuHQlnroTcHZVnVNV1wGfAp7QaXGSJEnSBPTR5/olSX7adhu54wzLNwd+OzJ9XjtPkiRJWtQWOly/H7gnsAPwO+Dtq/qCSfZNsjzJ8osvvnhVX06SJElaaQsarqvqwqq6sapuAj5E0wVkuvOBLUemt2jnzfaah1TVsqpatmTJkm4LliRJkuZhQcN1kruNTP4dcOYMq/0Y2CbJ3ZPcBngacPRC1CdJkiStinUm9cJJjgR2ATZJch7wemCXJDsABZwLvLBddzPgw1W1R1XdkOQlwNeBtYFDq+pnk6pTkiRJ6srEwnVV7TXD7I/Msu4FwB4j08cCtxqmT5IkSVrMvEOjJEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1BHDtSRJktQRw7UkSZLUEcO1JEmS1JGJheskhya5KMmZI/PemuSXSX6a5KgkG8/y3HOTnJHktCTLJ1WjJEmS1KVJtlx/FNh92rzjgftX1QOA/wZePcfzH1FVO1TVsgnVJ0mSJHVqYuG6qk4ALp0277iquqGdPAnYYlI/X5IkSVpoffa5fh7w1VmWFXBcklOS7LuANUmSJEkrbZ0+fmiS1wI3AJ+cZZWdq+r8JHcBjk/yy7YlfKbX2hfYF2CrrbaaSL2SJEnSOBa85TrJc4DHAntXVc20TlWd336/CDgK2Gm216uqQ6pqWVUtW7JkyQQqliRJksazoOE6ye7AvwGPr6prZllngyQbTT0GdgPOnGldSZIkaTGZ5FB8RwI/BLZNcl6SfYCDgY1ounqcluQD7bqbJTm2feqmwPeSnA6cDBxTVV+bVJ2SJElSVybW57qq9pph9kdmWfcCYI/28TnA9pOqS5IkSZoU79AoSZIkdcRwLUmSJHXEcC1JkiR1xHAtSZIkdcRwLUmSJHXEcC1JkiR1xHAtSZIkdcRwLUmSJHXEcC1JkiR1xHAtSZIkdWRitz+XtHpbut8xfZcwo3MP2rPvEiRJazBbriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI6MHa6TbJBk7UkWI0mSJA3ZrOE6yVpJnp7kmCQXAb8Efpfk50nemuReC1emJEmStPjN1XL9beCewKuBu1bVllV1F2Bn4CTgzUmesQA1SpIkSYOwzhzLHlVV10+fWVWXAp8HPp9k3YlVJkmSJA3MrOF6erBOsj7wDOC2wBFVdclM4VuSJElaU81ntJB3A9cBfwS+OJlyJEmSpOGa64LGI5Pcc2TWnYDP0nQJueOkC5MkSZKGZq4+168F3pTkd8CBwNuAo4D1gQMmX5okSZI0LHP1uT4HeHqSnYFPA8cAe1bVjQtVnCRJkjQkc3ULuWOSFwPbAU+m6Wv99SSPW6jiJEmSpCGZ64LGLwKXAQUcXlWHA48DHpjkywtRnCRJkjQkc/W5vjPwOZqh914IUFXXAm9McrcFqG0wlu53TN8lzOjcg/bsuwRJkqQ1ylzh+vXA14Abgf1GF1TV7yZZlCRJkjREc13Q+HmaYfckSZIkjWGuCxo/lOT+syzbIMnzkuw9udIkSZKkYZnrgsb3Avsn+UWSzyZ5X5JDk5wI/ADYiKZP9qza9S9KcubIvDslOT7JWe33GW9Ik+TZ7TpnJXn2Srw3SZIkaUHN1S3kNOApSTYElgF3A64FflFVvxrz9T8KHAx8fGTefsA3q+qgJPu1068afVKSO9H0+V5GM1rJKUmOrqo/jvlzJUmSpAU31wWNAFTVVcB3VubFq+qEJEunzX4CsEv7+GPta79q2jqPBo6vqksBkhwP7A4cuTJ1SJIkSQthrm4hk7LpyGgjvwc2nWGdzYHfjkyf186TJEmSFq0+wvVfVFXRdPtYaUn2TbI8yfKLL764o8okSZKk+VthuE7yVx3/zAunbkLTfr9ohnXOB7Ycmd6inXcrVXVIVS2rqmVLlizpuFRJkiRpfOO0XL8vyclJ/inJHTr4mUcDU6N/PBv40gzrfB3YLckd29FEdmvnSZIkSYvWCsN1VT0c2JumJfmUJEck2XWcF09yJPBDYNsk5yXZBzgI2DXJWcCj2mmSLEvy4fZnXgocCPy4/Xrj1MWNkiRJ0mK1wtFCAKrqrCSvA5YD/wU8MEmA11TVF+Z43l6zLPrbGdZdDjx/ZPpQ4NBx6pMkSZIWg3H6XD8gyTuBXwCPBB5XVfdtH79zwvVJkiRJgzFOy/V7gA/TtFJfOzWzqi5oW7MlSZIkMV643hO4tqpuBEiyFrB+VV1TVYdPtDpJkiRpQMYZLeQbwG1Hpm/XzpMkSZI0YpxwvX57C3TgL7dDv93kSpIkSZKGaZxwfXWSHacmkvw1cO0c60uSJElrpHH6XL8c+GySC4AAdwWeOtGqJEmSpAFaYbiuqh8nuQ+wbTvrV1V1/WTLkiRJkoZnrJvIAA8Clrbr75iEqvr4xKqSJEmSBmiF4TrJ4cA9gdOAG9vZBRiuJUmSpBHjtFwvA7arqpp0MZIkSdKQjTNayJk0FzFKkiRJmsM4LdebAD9PcjLw56mZVfX4iVUlSZIkDdA44fqASRchSZIkrQ7GGYrvu0m2Brapqm8kuR2w9uRLkyRJkoZlhX2uk7wA+BzwwXbW5sAXJ1mUJEmSNETjXND4YuBhwBUAVXUWcJdJFiVJkiQN0Tjh+s9Vdd3URJJ1aMa5liRJkjRinHD93SSvAW6bZFfgs8CXJ1uWJEmSNDzjhOv9gIuBM4AXAscCr5tkUZIkSdIQjTNayE3Ah9ovSZIkSbNYYbhO8mtm6GNdVfeYSEWSJEnSQI1zE5llI4/XB54M3Gky5UiSJEnDtcI+11V1ycjX+VX1LmDPBahNkiRJGpRxuoXsODK5Fk1L9jgt3pIkSdIaZZyQ/PaRxzcA5wJPmUg1kiRJ0oCNM1rIIxaiEEmSJGnoxukW8i9zLa+qd3RXjiRJkjRc444W8iDg6Hb6ccDJwFmTKkqSJEkaonHC9RbAjlV1JUCSA4BjquoZkyxMkiRJGppxbn++KXDdyPR17TxJkiRJI8Zpuf44cHKSo9rpJwIfm1xJkiRJ0jCNM1rIfyT5KvDwdtZzq+onky1LkiRJGp5xuoUA3A64oqreDZyX5O4TrEmSJEkapBWG6ySvB14FvLqdtS7wiUkWJUmSJA3ROC3Xfwc8HrgaoKouADaaZFGSJEnSEI0Trq+rqgIKIMkGky1JkiRJGqZxwvVnknwQ2DjJC4BvAB+abFmSJEnS8Mw5WkiSAJ8G7gNcAWwL7F9Vxy9AbZIkSdKgzBmuq6qSHFtVfwUYqCVJkqQ5jNMt5NQkD5p4JZIkSdLAjXOHxgcDz0hyLs2IIaFp1H7AJAuTJEmShmbWcJ1kq6r6X+DRC1iPJEmSNFhztVx/Edixqn6T5PNV9fcLVZQkSZI0RHP1uc7I43tMuhBJkiRp6OYK1zXLY0mSJEkzmKtbyPZJrqBpwb5t+xhuvqDx9hOvTpIkSRqQWcN1Va29kIVIkiRJQzfOONeSJEmSxrDg4TrJtklOG/m6IsnLp62zS5LLR9bZf6HrlCRJkuZrnJvIdKqqfgXsAJBkbeB84KgZVj2xqh67kLVJkiRJq6LvbiF/C/xPVf2m5zokSZKkVdZ3uH4acOQsyx6a5PQkX01yv4UsSpIkSVoZvYXrJLcBHg98dobFpwJbV9X2wHto7hY52+vsm2R5kuUXX3zxZIqVJEmSxtBny/VjgFOr6sLpC6rqiqq6qn18LLBukk1mepGqOqSqllXVsiVLlky2YkmSJGkOfYbrvZilS0iSuyZJ+3gnmjovWcDaJEmSpHlb8NFCAJJsAOwKvHBk3osAquoDwD8A/5jkBuBa4GlV5S3YJUmStKj1Eq6r6mrgztPmfWDk8cHAwQtdlyRJkrQq+h4tRJIkSVptGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjqzTdwGSJGlhLN3vmL5LmNG5B+3ZdwlSZ2y5liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI6YriWJEmSOmK4liRJkjrSW7hOcm6SM5KclmT5DMuT5L+SnJ3kp0l27KNOSZIkaVzr9PzzH1FVf5hl2WOAbdqvBwPvb79LktSLpfsd03cJszr3oD37LkESi7tbyBOAj1fjJGDjJHfruyhJkiRpNn2G6wKOS3JKkn1nWL458NuR6fPaeZIkSdKi1Ge3kJ2r6vwkdwGOT/LLqjphvi/SBvN9Abbaaquua5QkSZLG1lvLdVWd336/CDgK2GnaKucDW45Mb9HOm/46h1TVsqpatmTJkkmVK0mSJK1QL+E6yQZJNpp6DOwGnDlttaOBZ7WjhjwEuLyqfrfApUqSJElj66tbyKbAUUmmajiiqr6W5EUAVfUB4FhgD+Bs4BrguT3VKkmSJI2ll3BdVecA288w/wMjjwt48ULWJUmSJK2KxTwUnyRJkjQohmtJkiSpI33foVGSJEmL3GK9O+livDOpLdeSJElSRwzXkiRJUkcM15IkSVJHDNeSJElSRwzXkiRJUkcM15IkSVJHDNeSJElSRwzXkiRJUkcM15IkSVJHDNeSJElSRwzXkiRJUkcM15IkSVJH1um7AGlVLN3vmL5LmNG5B+3ZdwmSJKkHtlxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR1Zp+8CJIMdujoAACAASURBVEmSxrF0v2P6LmFG5x60Z98laBGx5VqSJEnqiOFakiRJ6ojhWpIkSeqI4VqSJEnqiOFakiRJ6ojhWpIkSeqI4VqSJEnqyIKH6yRbJvl2kp8n+VmSl82wzi5JLk9yWvu1/0LXKUmSJM1XHzeRuQF4RVWdmmQj4JQkx1fVz6etd2JVPbaH+iRJkqSVsuAt11X1u6o6tX18JfALYPOFrkOSJEnqWq99rpMsBR4I/GiGxQ9NcnqSrya534IWJkmSJK2EPrqFAJBkQ+DzwMur6oppi08Ftq6qq5LsAXwR2GaW19kX2Bdgq622mmDFq6+l+x3TdwkzOvegPfsuQZIkaV56ablOsi5NsP5kVX1h+vKquqKqrmofHwusm2STmV6rqg6pqmVVtWzJkiUTrVuSJEmaSx+jhQT4CPCLqnrHLOvctV2PJDvR1HnJwlUpSZIkzV8f3UIeBjwTOCPJae281wBbAVTVB4B/AP4xyQ3AtcDTqqp6qFWSJEka24KH66r6HpAVrHMwcPDCVCRJkiR1wzs0SpIkSR3pbbQQSeqTo+RIkibBlmtJkiSpI4ZrSZIkqSOGa0mSJKkj9rmWemS/X0mSVi+2XEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR0xXEuSJEkdMVxLkiRJHTFcS5IkSR1Zp+8CJEnzs3S/Y/ouYUbnHrRn3yVIUu9suZYkSZI6YriWJEmSOmK4liRJkjpiuJYkSZI64gWNkiRJE+aFyGsOW64lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjhiuJUmSpI4YriVJkqSOGK4lSZKkjvQSrpPsnuRXSc5Ost8My9dL8ul2+Y+SLF34KiVJkqT5WfBwnWRt4L3AY4DtgL2SbDdttX2AP1bVvYB3Am9e2ColSZKk+euj5Xon4OyqOqeqrgM+BTxh2jpPAD7WPv4c8LdJsoA1SpIkSfPWR7jeHPjtyPR57bwZ16mqG4DLgTsvSHWSJEnSSkpVLewPTP4B2L2qnt9OPxN4cFW9ZGSdM9t1zmun/6dd5w8zvN6+wL7t5LbAryb8FiZtE+BW73NAhlz/kGuHYdc/5Nph2PUPuXYYdv1Drh2sv09Drh2GXz/A1lW1ZKYF6yx0JcD5wJYj01u082Za57wk6wB3AC6Z6cWq6hDgkAnU2Ysky6tqWd91rKwh1z/k2mHY9Q+5dhh2/UOuHYZd/5BrB+vv05Brh+HXvyJ9dAv5MbBNkrsnuQ3wNODoaescDTy7ffwPwLdqoZvYJUmSpHla8JbrqrohyUuArwNrA4dW1c+SvBFYXlVHAx8BDk9yNnApTQCXJEmSFrU+uoVQVccCx06bt//I4z8BT17ouhaJoXdxGXL9Q64dhl3/kGuHYdc/5Nph2PUPuXaw/j4NuXYYfv1zWvALGiVJkqTVlbc/lyRJkjpiuJYkSZI6YriWJEmSOmK4XkSSrJXk9n3XMR9JTkny4iR37LsWDUuS9ZI8Pclrkuw/9dV3XWuCJC9Lcvs0PpLk1CS79V3XmiDJk5Ns1D5+XZIvJNmx77rGleR2Sf49yYfa6W2SPLbvurT4JbnLDPO27aOWSTNc9yzJEe0/uQ2AM4GfJ/nXvuuah6cCmwE/TvKpJI9Okr6LGleSJyU5K8nlSa5IcmWSK/qua1xJ1m8Pbt6X5NCpr77rGtOXgCcANwBXj3wNwsC3/fOq6gpgN+COwDOBg/otaXwD32//vaquTLIz8CiaoWff33NN83EY8Gfgoe30+cCb+itnfpKckeSn075OTPLOJHfuu765tAcyn0vy8yTnTH31Xdc8nJjkKVMTSV4BHNVjPRNjuO7fdu0/uScCXwXuTvOPbhCq6uyqei1wb+AI4FDgN0nekORO/VY3lrcAj6+qO1TV7atqo6oa0tmDw4G7Ao8Gvktzx9Mre61ofFtU1VOr6i1V9fapr76Lmochb/upA+A9gMOr6mcj84ZgyPvtje33PYFDquoY4DY91jNf96yqtwDXA1TVNQzrs/NV4Bhg7/bry8By4PfAR/srayyH0RyI3QA8Avg48IleK5qfXYBnJvlskhNocsNO/ZY0GYbr/q2bZF2acH10VV0PDGp8xCQPAN4OvBX4PM0Y5VcA3+qzrjFdWFW/6LuIVXCvqvp34Oqq+hjNP+wH91zTuH6Q5K/6LmIVDHnbn5LkOJpw/fW2m8JNPdc0H0Peb89P8kGas37HJlmPYf0vvi7JbWn/TyW5J01L9lA8qqpeXVVntF+vBf6mqt4MLO25thW5bVV9k2YY5d9U1QE0f3cGoap+B3yN5qzHUuBjVXVVr0VNSC83kdEtfBA4FzgdOCHJ1jTBdBCSnAJcRnNqc7+qmvoj+6MkD+uvsrEtT/Jp4IuM/IOoqi/0V9K8XN9+vyzJ/WlaX27Vr22R2hl4TpJf02z7AFVVD+i3rLENedvvA+wAnFNV17Snw5/bc03zMeT99inA7sDbquqyJHcDhtQV8PU0AWnLJJ8EHgY8p9eK5mftJDtV1ckASR5Ec7doaFqEF7M/J1kLOKu90/X5wIY91zS2JN8ALgDuD2wJfCTJCVX1yn4r6543kVmEkqxTVYt9JwcgyT2qakh9vm4hyWEzzK6qet6CF7MSkjyf5mzBA2hOGW4I7F9VH+i1sDG0B5K3UlW/WehaVsYQt32S+1TVL2e7gK6qTl3omlbGkPfbtqX3vKr6c5JdaD4/H6+qy/qtbHztwdhDaA6IT6qqP/Rc0tjaMH0ozf4amsas5wM/A/asqs/0WN6c2tp/AWwMHAjcAXhLVZ3Ua2FjSvLEqvriyPQ6wKur6sAey5oIw3VPkjyjqj6R5F9mWl5V71jomuZjtrqnLPb6tTgk2R54eDt5YlWd3mc9q7skh1TVvkm+PcPiqqpHLnhRa5gkpwHLaE6LH0tzYe/9qmqPPutakRWNaDKUA7MpSe4AUFWX912LVj92C+nPBu33jXqtYuUNte5bSLIF8B6aU5sAJwIvq6rz+qtqfEk2Bp5F84/6L/tzVb20r5rGleRlwAuAqVP5n2jD33t6LGtsQ9z2VbVv+/0RfdeyKga+395UVTckeRLwnqp6T5Kf9F3UGOa62LiAQRyYtX3c/552v50a3Kqq3thjWXNK8q6qenmSLzPDNVlV9fgeypq3JA+h2W/vS3MR79rAVVV1h14LmwBbrrVGS3I8zSgnh7ezngHsXVW79lfV+JL8ADgJOIORC9LaC+wWtSQ/BR5aVVe30xsAPxxKn+uBb/snA19rh4R7HbAjcGBVDSHkDXq/TfIj4F3Aa4HHVdWvk5xZVffvubQ1QpKvAZcDp3DzyC0s5pGKkvx1VZ2S5G9mWl5V313omlZGkuXA04DP0py9eRZw76p6da+FTYDhumdJ3kIzRui1NBeJPAD456oaxPA6SdanuTjqfsD6U/OH0PcRmlO0VbXDiuYtVklOrarB3IBiVJIzgAdV1Z/a6fWBH1fVIEYQGfi2/2lVPaAda/lNNCP97F9VgxjtZMj7bZLtgBfRHEgemeTuwFPa0SoWvSTPmml+VX18oWtZGR7I9CfJ8qpaNvX3p533k6p6YN+1dW1Iw/+srnZrx7l+LM2oIfdiWFeOD3msX4BLkjwjydrt1zOAS/ouah4OT/KCJHdLcqepr76LGtNhNKPKHJDkAJpW4I/0W9K8DHnbD32s5cHut1X186p6aVUd2U7/eijBuvWgka+HAwcAg+iW0BrsEKBJHpbk+CT/neYGMr/OsG4ic02S2wCnJXlLkn9mNc2htlz3bOooOsmHgc9V1deSnF5V2/dd2zimjjpHWsLWpbkw7SF91zaOdsSK99CMu1nAD4CXVtX/9lrYmJK8GPgPmuEQp3bmqqp79FfV+NqLpHZuJ08cSrcEGPa2T/IVmmG8dqXpEnItcPKA/u4Mdr9Nsg3wf4HtuOXZvkX/uZlJe+3Bp6pq975rGUeSn9M0Yg1uCNAkvwT+mVt3aRnEgWW7315IcyD/zzSjnbyvqs7utbAJMFz3LMlBNDeQuZbmTkUbA18Z0OnZk6tqpzR3W/onmrF+Tx7qP4qhaVstdhrYUFi3r6orZmvlrapLF7qmlTHEbT8lye1oxlo+o6rOSjPW8l9V1XE9l7baS/I9mrGi3wk8jmZ88bWqav9eC1tJbYPKmVW1bd+1jGPIQ4Am+dFQssF0SdamGXJy775rWQiOFtKzqtqv7Xd9eVXdmORq4Al91zUPhyS5I/DvwNG0Y/32W9KKJfm3qnpLkvcw89XXi3bEh2nOBq7pu4h5OoKmG9Qp3HLbp50eyoHZELc90NyyOsn/AI9O8miaswaLPlivJvvtbavqm0nSBroD0tyMa9H/3QSYNmLFWjQt8It2bOgpUwf1DKvb4nTfTvJWmhGWRm+etOiHQWzzzdZJblNV1/Vdz6QZrheHzYBHtRd0TRnExSFV9eH24XcZTiiCZiB+gOW9VrHqrqbpv/ZtbvnHdtGGjKp6bPv97n3XsooGt+2nDHgYxNVhvx30XfaAt408vgH4zUCGQJx+UJ+RZUM5qJ9qtV42Mm8wwyAC5wDfT3I0zd9PYPW8L4bdQnqW5PXALjRH/8cCjwG+V1X/0Gdd48rMN5O5HDilqk5b6HrmK8mTq+qzK5q3WCV59kzzBzIc3MOA06rq6vaCtB2Bdw2h3ywMftsPfRjEwe63Gfhd9qSV1eadW6mqNyx0LZNmuO5ZOxzZ9sBPqmr7JJsCnxjCeK0ASY6gOYr+cjvrscBPaQbo/2xVvaWn0sYy03BqQxtiLcltga2q6ld91zIfbcDbnmb4yY8CH6YZkmzGsVwXowFv+9VuGMSh7bdDk+RKZuiKM6Wqbr+A5aySJJsDW3PLmz+d0F9F40lzV8nXA/+nnfVd4I01sLtMJtkQoKqu6ruWSbFbSP+uraqbktyQ5PbARcCWfRc1D1sAO07tJO2R6TE0O/8pwKIM10keA+wBbJ7kv0YW3Z7mVOcgJHkczWna2wB3T7IDzR/bIQyNdUNVVZInAAdX1UeS7NN3UeMa+LafGgbxqHb6iQxgGMQh77ftqfBZLfbPTVVtBJDkQOB3NMOwBtgbuFuPpc1LkjcDTwV+zs0jbhSw6MM1cChwJvCUdvqZNPvyk3qraB6S3J/mc3OndvoPwLOq6me9FjYBhuv+LW+HMvoQTRi9CvhhvyXNy10Y6W8KXA9sWlXXJvnzLM9ZDC6g6bf5eJrtPuVKmiGChuIAmlFmvgNQVaclGULfQYArk7ya5u56/6fth7puzzXNxwEMcNu32/kkmrqnhkF87kCGQRzyfvtQ4LfAkcCPuGWf3yF5/LQhG9+f5HQGckEmzYHktlW1mP8/zeaeVfX3I9NvSLLou1+OOAT4l6r6NkCSXWiyz//XZ1GTYLjuWVX9U/vwA2luy3r7qvppnzXN0ydpWsC+1E4/Djii7cP58/7KmltVnQ6cnuSIqrq+73pWwfVVdXlyi//TN8228iLzVODpwD5V9fskW9HcKXAoBrnt2zNl723virboRxkYNfD99q4044rvRfO5PwY4coCtdlcn2Rv4FE2L716MXJw2AOfQHMQPMVxfm2Tnqvoe/OW6lWt7rmk+NpgK1gBV9Z02K6x27HPdsyTfrKq/XdG8xSzJMuBh7eT3q2owV/IP/YYOST4CfBPYD/h74KXAulX1ol4LWwMMedsneRvNGbIv1AD/CawG++16NKH0rcAbqurgnksaW5KlwLu5+W/+94CXV9W5PZU0L0k+T3OtxzcZ3ig/OwAfo7kINsClwHPag85Fr+2GdipN1xBozlr+dVX9XX9VTYbhuiftBUS3A75NM1rIVPPX7YGvVdV9eipt3pLsDGxTVYclWQJsWFW/7ruucQz9hg7tzUBeC+xG8xn6OnDg1IVqi9m0C6RuQ9OadFVV3aG/qsa3Gmz7DWj6nE7VW0O5KG2o+20bqvekCdZLae4NcGhVnd9nXWuSIY/yM6W9Pot23O7BaO+J8QZG7soLHFBVf+yvqskwXPekHWf25TRjXJ/PzeH6CuBDQ2nJaC9gXEbTh+3eSTajGSXkYSt46qKQ5JSq+uskZ0yNlDA1r+/a1iRp+lY8AXhIVe3Xdz3zlebuYxsM7Z/dUA1xv03yceD+NEOufqqqzuy5pJWSZAuaW89P/Y0/EXjZQMa6BgY9ys/GwLNoDsxGRzpZ9K3uaxrDdc+S/P8DuHHDrNqLKR4InNr24STJTwc0Xu4PaI6iPwd8i+ZA56Ba5LfyzS3vknYri33kgdkk+cnU52ixa4ehfBFN6++Pac46vbuqBtFvPMmTaD77RXOHxi/2XNLYhrjfJrmJm/sm3+rOpAM6a3A8zQ1ZRk/t7z2g4WP/MspPVQ1qlJ/2c38ScAYj13cMpdU9yb2BV3Lrg4Oh3ARnbF7Q2L+bkmxcVZfBX06b7FVV7+u5rnFd1w6nVvCXm1EMyctouue8lOaGDo8EZjxtuMhM3SXtSTQXSn2ind4LuLCXiuapDXdT1qI5A7Lou1SM2K6qrmgv7voqTd/rUxjARZlJ3gfci2bkCoAXJdm1ql7cY1nzMX2/fQSLfL+tqrX6rqEjS6rqsJHpjyZ5eW/VzN8BDHCUn9b6VTXTjduG4rPAB2juaXDjCtYdNMN1/15QVe+dmqiqPyZ5ATCUcP2ZJB8ENm7rfh7N0DqDUFU/bh9eRdNvcxCq6rsASd5eVaO3wv1ykqFcUPq4kcc3AOfSdA0ZinWTrEsztNfBVXX91EHmADwSuO/UxYxJPgYMYtSKtgvOU6vqlQxsv11NXJLmjqpTB2Z7AZf0WM98DXKUn9bh7f/Zr3DLizEv7a+kebmhqt7fdxELwXDdv7WTZOSf3No0F3cNQlW9LcmuNH3FtwX2r6rjey5rhVajbhUbJLlHVZ0DkOTuNBeqLVpJ3lxVrwK+WlWf6bueVfBBmgOC04ETkmxNsx8MwdnAVsBv2ukt23mLXlXd2F5ErX48j6bP9Ttp/ob+gGEd4PwsydNp/vduQ3P24wc91zSu62jOjL2Wm/9/FbCoW96T3Kl9+OUk/wQcxTAPDsZmn+ueJXkrzW1YP9jOeiHw26p6RX9VzV979fJoH6pFvbMkmbrF9ozdKqpqsd+QAoAku9MMzH8OTd/NrYEXVtXXey1sDmluvf0A4JQa8O2qk6xdVTeOTAdYu6oW7Z0CRw4q7wA8CDi5nX4wcHJV7dJfdeNL8n5gc5rTzH8ZY7mqvtBbURqEaaP8ABxH0+d60Y97neQcYKeq+kPftcxHkl/T/J2Z6cZJNZQhNOfDcN2z9m5pLwSmxrU+Hvjw6D/txSzJC2mG1vkTzam1qYtzBrGzJFk+rVvFjPMWs3Z4r6mhG3+52P9JtAeULwA2BK4ZXcSwLuw6h+aCusOq6hd91zOOkYPKGU11N1rskhw2w+yqqucteDFriCRzDXNYVXXgghWzCpLsU1UfmTbvoCGMUpTkOOCJVXXNCldehJKsP32o0pnmrQ4M14vAUIcFAkhyFvDQoR1JT0nyC2DPad0qjq2q+/Zb2dyS/FtVvaV9/OSq+uzIsv+sqtf0V93ckqxXVX9O8qWqGlIf61tIshHwNNoxloFDaYZYG0rXkMFK8rCq+v6K5qk7SWY6m7oBsA9w56racIFLWilJjgU+WVWfbKcPBm5bVfv0W9mKtTdhuR/N/TEGdQMcgCSnTj9bOdO81YHhumdJHk/Th2pwwwIBpLll+5MGfCQ9uG4VcMs/SNP/OC32P1ZT9SU5vKqe2Xc9XWhbhI8ANqZpzT6wqhZdH+Yk36uqnXPLG/jA8M4arDH/pBej9sDyZTTB+jPA26vqon6rGk/bmHU0zcHw7sBlVfWy/9fevcfsWd91HH9/CmVlk4qMDoIsBWnAEU5CIaywRTCoHQdhHHZgbmqYgWAGI1FTF8eYyuJh0whRyYZyGMOChIZx3CYIXckolCFlMrYRrFF2yDBDBjja+vGP67p57j59zqff/bvuzytpel/X/TzJp02f3r/rur6/77dsqqlRpQNwJO1LU8b1eeD97Dg07+9c0dC8qcqGxvIuZ+e2QAcWTTQ9a4CHJT1ChVfStu9tN7VUU1bR0jivxzoeNLu1G4pWjWrHB9RTN9tuPj6V5s71AcCngZuAd9AMCjm4WLjxnQ9ge4/SQWZC0tuBVcAySf0tyZYCu5RJNTzajWmX0fw7uh442pVM1+vbVAdwAbAO2ABcIWmvQd8nBIO/iJ7ArwC/AewPfKbv/EvAwD5lnY0srssbqy1QTY8TrqEZ4rBDU/tBJ+lk2/ePsbg7SFINCzyP83qs40FzIc2H857s2I4PmuyD/nff822ax7N/bru/28A/SXpnoUyTuR3oPfG4zfbZhfNM1240tfq7Av0XCP8DnFMk0ZBo90q8m+ZJ3+G2f1w40nRtYmRTXe/3U9tfA99xA3bYGLiDQd/j1F4UXC/pbNu3lc6zEFIWUpika4F/phlAcTZNW6DFti8sGmyKVNFEvX6SrrB9ea0boyRtp+mSIGB3RjYGimbQwOJS2aZqrI1FNZH0U7UtMPp/Xmv92QWQtNz2lsm/MuaKmgmTP6HpSV9tSVHNJL2573AJcC6wl+2JNpsODDXj2z8O9G4+PEhTBvtiuVTzI4vrwka1BRJwH029ZhW7ZyVdSdPr94t0vG9lzI2aN2P2k7SMpuvJAezYhnJgL8wmqtWvQYf600chki6m2dBY61TkHUjaZPuY0jmmQtJtwFM0JUUAvw4caXun8sDaZXEds9I+phpt4FvxjarX3Intz0z0fsxczZsx+0l6GFhP87j59daZg/zYc5InHgN/97ErrQSjHElP2D5q1LkqnuJI6v+/cRGwErjI9pGFIk3LOH/3O53rgtRcF9KVOzC2a9p82a/KDV0dUfNmzH5vdDNpshq2q970l8VzzIGapyJ/uu/1NpqnxueViTIjr0o60fZXoWmfCbxaONO8yOK6nL8oHWAuSFoMXMRIDdW/ANfY3los1BTYvqJ0hiFW82bMfndKepftu0sHGRaSbrF9npopn2Nt7DqiQKyoy73AWkn9U5HvLZhnymyfVDrDLF1Es7Hxp2lupPw3TReRzklZyACofIjM54DF7FhDtd32BeVSTZ2k/YGrgBPaU+uBS2z/Z7lU3Vb7Zsy+HtGiGaLxGtC7mBz40oqaSdrP9vOSlo/1fjY5xmRU8VRkSfsAVwL72V4t6VCaIW5VbQyXtBSgywO3srguTNLpNHexax0i86+j673GOjeoJH2ZZvjHje2pDwDn2z6lXKqIGEsXBxBFTJWke4B/AD5m+0hJuwJft3144WhT0nYL+SA7bwKvYi7GdKQspLxPUPcQme2SDrL9LICkn6Nvc1cFltnub8d3naRLi6WJqrR90k+kuZO93va6wpG6rhMDiGLhdaSkaG/bt0haA2B7W/sksBZ3A1+jsrkYM5HFdXm1D5H5XeABSf3jw3+zbKRpeUHSB4Cb2+P3AS8UzBOVkPQ3wApG/u1cKOkU2xcXjNV1XRlAFAuvN+L8tKIpZuflttd1bzPm8UBNPaKX2J6wU1dXpCyksNqHyABIegNwSHv4TCXjw4FmGAVNzfXb21MbgI/Y/o9yqaIGkr4JvK2v68Ai4Bu231Y2WffVPoAoYibaVnxXAYfR9IteBpxj+8miwaZI0keBHwN30vG5GFlcFzZqiAyMDJEZ6AXqBOPDgTyeje6TdCdwcW8TXXuhdrXt0XdUYx5IWsXOtZs3FAsUVWg/s/4UeAvN09Yqerz3tHXWh9DkfmbQO3P1awf4/AnwI0ae0A/8XIyZyOK6sNET6sY7N2hqHx/eI+nPgD+m6bV5L3AE8FHbny8aLAaepAeBY4GN7aljgcdoH9PWsim5RpJuBA4CnmBkj4e7uDEq5pak7wCn2366dJaZqPmisi0fPc72D0tnmW9ZXBc21kS6mqbU1a43HUrSWTS1eJcBD9XS7STKybTAciQ9DRzqfIDFNEnaYPuEyb9y8NR+USnpS8CZtl+Z9Isrlw2NhUhaDbwL+FlJf9331h6M9MwdWB0aH977GTgVuHWMzaURY+otntuerf13kTpXPziAngL2Bb5bOkjUoa+E8TFJa4F17Fj3W0Mp40rqvqh8GXhC0gPs+HdfxcXBdGRxXc7zwCbgjPb3nuWMDNUYZL3x4YfQPA6/oz0+nZHH5DW4s92Y9ipwkaRlwP8WzhQVkPTbwCdp/r38H23tJtC5+sEBtDfwb5I2suOHdEpxYjz9eyFeYWSfE9TTaab2i8p17a/OS1lIYe348MOA9wPnAs8Bt9m+umiwKZL0EHCq7Zfa4z2Au2y/c+LvHByS9gJetL293WC61Pb3SueKwSbp2zTT0TpfPzhoxivJSSlOjEfS79TyuTqe9o7vUTQ3sHJROcBy57oQSQfT9FR+H/BDYC3Nxc5JRYNN3z404597XmvP1eTngQPaXdg9VWwQiaKepY6nTJ2TRXTMwG8BVS+uaYbOVUvSc4w9wKdzT/uyuC7nm8B64DTb34HXe0DW5gZgo6Tb2+MzgevKxZme8TaIkMV1TG4N8LCkR+h4/eCgkPQSYw/ZqqqdWsR0SFpCM0BpBc10w2ttbyubakZW9r1eQvO0fq9CWeZVykIKkXQm8F7gBJoWcP8IfM52NaPP1ez825+mkf072tMP2f56uVTTk64DMVNtve9XGTXK1/b1xUJFxJgkbWPsJ00Df2HWbsDcSnNDbjWwxfYlE39XHSRtsn1M6RxzGVcILAAABmFJREFULXeuC7G9Dlgn6U3ArwGXAm+R9LfA7ba/VDTgFNi2pLttHw48XjrPDNW+QSTKWTwso3wjOmCz7V8oHWKGDm0/Z3tTnWtqGvC6dsJkzyKaO9mdXId28g9VE9svA18AviDpZ2gek/w+MPCL69bjko61/WjpIDOUrgMxU/e0HUO+SMdH+UZEUa+357W9reJ2sZ/ue70N+HfgvDJR5lfKQmJW2jZ2K4AtND0se4/YjigabIrSdSBmqt2cM1onR/lG1E7SH9i+cgpft8b2pxYi01RJ2k7z+QrNZ+zuNCUuA1/SMqyyuI5ZkbR8rPO2tyx0lpmStA9Nr26AjbZ/UDJPRESUkQnJ86f9rL0S2M/2akmH0rQzvbZwtDm3qHSAqJvtLe1C+lWaXfy9X1WQdB5N/dq5NI+nHpF0TtlUMcgk/V7f63NHvTfpnbGIGGjV1lxU4DrgPmC/9vhbNPvNOieL65gVSWe0wzSeAx6kqaG6p2io6fkYcKztD9n+IHAc8IeFM8Vge2/f6zWj3vvVhQwSEXOumptDFdrb9i203ZXadoLbJ/6WOmVxHbP1R8DxwLfaNoK/BHytbKRpWTSqDOQF8nMRE9M4r8c6joi65Gd4/rws6c20FzCSjgdeLBtpfqRbSMzWVtsvSFokaZHtByT9VelQ03CvpPuAm9vj9wB3F8wTg8/jvB7rOCLqcmvpAB12GXAHcJCkDTQzMjpZhpkNjTErkr5CM5XxUzRt7X5AU2axqmiwSUhaAexje4OkdwMntm/9CLjJ9rPl0sUg69u5379rn/Z4ie3FpbJFxNgkXcUEF7+ZrLowJO0KHELz/+UztrdO8i1VyuI6ZqS3OKUZG/4qTSnF+cBy4C7bmwrGm5SkO4E1tjePOn84cKXt08ski4iIuSbpQxO9n8mqC0PSKuAA+ionbN9QLNA8yeI6ZqT2xamkR20fO857m3vTsCIiImL2JN0IHERzU663kdFdfGqQmuuYqX1GL6wBbG+WdMDCx5m2PSd4b/cFSxEREQtG0jKaKciHAkt6522fXCzU8FhJM8q983d10xUhZqr2xeljkj48+qSkC4CBLmmJiIgZuwl4GjgQuIKmfeyjJQMNkaeAfUuHWAgpC4kZkXQzcL/tz446fwFwiu33lEk2Ne2kqNuB1xhZTK8EdgPOsv29UtkiImJ+SNpk+xhJT9o+oj03bplgzB1JDwBH0Qxu+0nvvO0zioWaJykLiZm6FLhd0vmMsTgtlmqKbH8fWCXpJOCw9vRdtu8vGCsiIuZXrzvFdyWdCjwP7FUwzzD5ROkACyV3rmNWRi1Ov5HFaUREDCpJpwHrgbcCVwFLgSts31E0WIdJWgJcCKwANgPXttMZOyuL64iIiOg8SbsAH7H9l6WzDBNJa2meGKwHVgNbbF9SNtX8yuI6IiIihoKkjbaPK51jmPS3t22HyGy0fXThWPMqNdcRERExLDZIuhpYSzNpFQDbj5eL1HmvT2G0vU1SySwLIneuIyIiYii0HStGc/pczx9J2xm5kBFNu95X2te2vbRUtvmSxXVERERExBxJWUhEREQMBUkfH+u87U8udJboriyuIyIiYli83Pd6CXAazcTGiDmTspCIiIgYSpLeANxn+xdLZ4nuWFQ6QEREREQhbwT2Lx0iuiVlIRERETEUJG0Geo/sdwGWAam3jjmVspCIiIgYCpKW9x1uA77f9VHcsfBSFhIRERFDwfYW4K3Aybb/C9hT0oGFY0XH5M51REREDAVJlwMrgUNsHyxpP+BW2ycUjhYdkjvXERERMSzOAs6gbcln+3lgj6KJonOyuI6IiIhh8ZqbR/YGkPSmwnmig7K4joiIiGFxi6RraGqtPwx8Bfhs4UzRMam5joiIiKEh6RTglwHRDJD5cuFI0TFZXEdEREREzJEMkYmIiIhOk/QSTZ21GBkiQ+/Y9tIiwaKTcuc6IiIiImKO5M51REREdJqkJcCFwArgSeDvM5kx5kvuXEdERESnSVoLbAXWA6uBLbYvKZsquiqL64iIiOg0SZttH96+3hXYaPvowrGio9LnOiIiIrpua+9FykFivuXOdURERHSapO20I89pOoTsDrxCuoXEPMjiOiIiIiJijqQsJCIiIiJijmRxHRERERExR7K4joiIiIiYI1lcR0RERETMkSyuIyIiIiLmyP8Dir0eInu738oAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "label_counts = 100*np.mean(all_xray_df[all_labels].values,0)\n",
        "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
        "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
        "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
        "ax1.set_xticklabels(all_labels, rotation = 90)\n",
        "ax1.set_title('Adjusted Frequency of Diseases in Patient Group')\n",
        "_ = ax1.set_ylabel('Frequency (%)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YGv8mwYIUGQY"
      },
      "outputs": [],
      "source": [
        "all_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "L-aF9NwEWWr-",
        "outputId": "78479282-389c-4102-acc9-317b82656ca5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Image Index Finding Labels  Follow-up #  Patient ID  Patient Age  \\\n",
              "54543   00013670_050.png   Infiltration           50       13670           56   \n",
              "20665   00005532_002.png   Infiltration            2        5532           37   \n",
              "107625  00029081_000.png                           0       29081           51   \n",
              "\n",
              "       Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
              "54543               M            AP                 2500     2048   \n",
              "20665               F            PA                 2992     2991   \n",
              "107625              M            PA                 2021     2021   \n",
              "\n",
              "        OriginalImagePixelSpacing[x  ...  Emphysema  Fibrosis Hernia  \\\n",
              "54543                      0.168000  ...        0.0       0.0    0.0   \n",
              "20665                      0.143000  ...        0.0       0.0    0.0   \n",
              "107625                     0.194311  ...        0.0       0.0    0.0   \n",
              "\n",
              "        Infiltration  Mass  Nodule  Pleural_Thickening  Pneumonia  \\\n",
              "54543            1.0   0.0     0.0                 0.0        0.0   \n",
              "20665            1.0   0.0     0.0                 0.0        0.0   \n",
              "107625           0.0   0.0     0.0                 0.0        0.0   \n",
              "\n",
              "        Pneumothorax                                        disease_vec  \n",
              "54543            0.0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
              "20665            0.0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
              "107625           0.0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "\n",
              "[3 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33b277bf-be2e-4ad8-a504-038daaa3e37b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "      <th>Follow-up #</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Gender</th>\n",
              "      <th>View Position</th>\n",
              "      <th>OriginalImage[Width</th>\n",
              "      <th>Height]</th>\n",
              "      <th>OriginalImagePixelSpacing[x</th>\n",
              "      <th>...</th>\n",
              "      <th>Emphysema</th>\n",
              "      <th>Fibrosis</th>\n",
              "      <th>Hernia</th>\n",
              "      <th>Infiltration</th>\n",
              "      <th>Mass</th>\n",
              "      <th>Nodule</th>\n",
              "      <th>Pleural_Thickening</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Pneumothorax</th>\n",
              "      <th>disease_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54543</th>\n",
              "      <td>00013670_050.png</td>\n",
              "      <td>Infiltration</td>\n",
              "      <td>50</td>\n",
              "      <td>13670</td>\n",
              "      <td>56</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20665</th>\n",
              "      <td>00005532_002.png</td>\n",
              "      <td>Infiltration</td>\n",
              "      <td>2</td>\n",
              "      <td>5532</td>\n",
              "      <td>37</td>\n",
              "      <td>F</td>\n",
              "      <td>PA</td>\n",
              "      <td>2992</td>\n",
              "      <td>2991</td>\n",
              "      <td>0.143000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107625</th>\n",
              "      <td>00029081_000.png</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>29081</td>\n",
              "      <td>51</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2021</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.194311</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33b277bf-be2e-4ad8-a504-038daaa3e37b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33b277bf-be2e-4ad8-a504-038daaa3e37b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33b277bf-be2e-4ad8-a504-038daaa3e37b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "all_xray_df.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAwaQtgN_4U3",
        "outputId": "a7befdf8-dc37-45a5-d1e8-a050d81aa73f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112120"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(all_xray_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWddu_dD42zn"
      },
      "source": [
        "### Get DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5Qon97klUzXo"
      },
      "outputs": [],
      "source": [
        "class NIH_Dataset(Dataset):\n",
        "  def __init__(\n",
        "    self, \n",
        "    data_df,\n",
        "    transform=None\n",
        "    ):\n",
        "    self.data_df = data_df\n",
        "    self.transform = transform \n",
        "\n",
        "  def __len__(\n",
        "    self\n",
        "    ):\n",
        "    return len(self.data_df)\n",
        "\n",
        "  def __getitem__(\n",
        "    self, \n",
        "    idx\n",
        "    ):\n",
        "    img_file = self.data_df['path'].iloc[idx]\n",
        "    img = Image.open(img_file).convert('RGB')\n",
        "    label = np.array(self.data_df.iloc[:,-1].iloc[idx], dtype=float)\n",
        "    if self.transform:\n",
        "        img = self.transform(img)\n",
        "\n",
        "    return img, label\n",
        "\n",
        "def get_data_loaders(\n",
        "    data_df: pd.DataFrame,\n",
        "    global_train_frac: float = 0.8,\n",
        "    local_train_frac: float = 0.8,\n",
        "    batch_size: int = 32,\n",
        "    num_clients: int = 10\n",
        "    ):\n",
        "  train_data_transform = T.Compose([\n",
        "    T.RandomRotation((-20,+20)),\n",
        "    # T.Resize((512,512)),\n",
        "    T.Resize((224,224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "\n",
        "  test_data_transform = T.Compose([\n",
        "    T.Resize((512,512)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "  \n",
        "  train_df, test_df = train_test_split(\n",
        "      data_df,\n",
        "      test_size = 1 - global_train_frac,\n",
        "      random_state = 42,\n",
        "      stratify = data_df['Finding Labels'].map( lambda x: x[:4])\n",
        "  )\n",
        "\n",
        "  trainset = NIH_Dataset(\n",
        "      train_df,\n",
        "      transform = train_data_transform\n",
        "      )\n",
        "  \n",
        "  testset = NIH_Dataset(\n",
        "      test_df,\n",
        "      transform = test_data_transform\n",
        "      )\n",
        "\n",
        "  # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "  partition_size = len(trainset) // num_clients\n",
        "  lengths = [partition_size] * num_clients\n",
        "  lengths[-1] += len(trainset) - np.sum(lengths)\n",
        "  datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "  # Split each partition into train/val and create DataLoader\n",
        "  trainloaders = []\n",
        "  valloaders = []\n",
        "  for ds in datasets:      \n",
        "      len_train = math.ceil(len(ds) * local_train_frac)\n",
        "      len_val = len(ds) - math.ceil(len(ds) * local_train_frac)\n",
        "      lengths = [len_train, len_val]\n",
        "      ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "      trainloaders.append(DataLoader(ds_train, batch_size=batch_size, shuffle=True, drop_last = True))\n",
        "      valloaders.append(DataLoader(ds_val, batch_size=batch_size, drop_last = True))\n",
        "  testloader = DataLoader(testset, batch_size=batch_size)\n",
        "\n",
        "  return trainloaders, valloaders, testloader\n",
        "\n",
        "def inv_data_transform(img):\n",
        "    img = img.permute(1,2,0)\n",
        "    img = img * torch.Tensor([0.229, 0.224, 0.225]) + torch.Tensor([0.485, 0.456, 0.406])\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rigzBUI_Wovp"
      },
      "outputs": [],
      "source": [
        "num_clients = 100\n",
        "\n",
        "trainloaders, valloaders, testloader = get_data_loaders(\n",
        "    all_xray_df,\n",
        "    global_train_frac = 0.95,\n",
        "    local_train_frac = 0.9,\n",
        "    num_clients = num_clients,\n",
        "    batch_size = 25\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "H5Oi7dIN3aWP",
        "outputId": "bc629779-8d78-4ce0-89e3-91eed15ef7b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(\n",
        "    inv_data_transform(\n",
        "        testloader.dataset[0][0]\n",
        "    )\n",
        ")\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh6Nm_YzvJpo",
        "outputId": "48f86f7b-ae4a-46b5-8e2c-ad57bbcc0594"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(959, 106, 5607)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(trainloaders[0].dataset), len(valloaders[0].dataset) ,len(testloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHFmMLT5aZ2h",
        "outputId": "1812deae-d9b1-4dec-d921-a2f32636416f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic FL utils"
      ],
      "metadata": {
        "id": "9o_uC5yi5e83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Read values from config\n",
        "        server_round = config[\"server_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "\n",
        "        # Use values provided by the config\n",
        "        print(f\"[Client {self.cid}, round {server_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=local_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ],
      "metadata": {
        "id": "RYlrQJOH5eRz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FL training utils"
      ],
      "metadata": {
        "id": "UwdUHQgA5qt8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZpaMF3WiAfkx"
      },
      "outputs": [],
      "source": [
        "def compute_class_freqs(labels):\n",
        "\n",
        "    labels = np.array(labels)\n",
        "    N = labels.shape[0]\n",
        "\n",
        "    positive_frequencies = np.sum(labels, axis = 0) / N\n",
        "    negative_frequencies = 1 - positive_frequencies\n",
        "\n",
        "    return positive_frequencies, negative_frequencies\n",
        "\n",
        "def weighted_loss(pos_weights, neg_weights, y_pred, y_true, epsilon = 1e-7):\n",
        "    y_pred = torch.sigmoid(y_pred)\n",
        "    loss = 0.0\n",
        "    for i in range(len(pos_weights)):\n",
        "        loss_pos = -1 * torch.mean(pos_weights[i] * y_true[:,i] * torch.log(y_pred[:,i] + epsilon))\n",
        "        loss_neg = -1 * torch.mean(neg_weights[i] * (1-y_true[:,i]) * torch.log((1-y_pred[:,i]) + epsilon))\n",
        "        loss += loss_pos + loss_neg\n",
        "    return loss\n",
        "\n",
        "def train(\n",
        "    net,\n",
        "    trainloader,\n",
        "    epochs\n",
        "    ):\n",
        "    print(f'Entered train function, total num. of epochs: {epochs}')\n",
        "    # ToDo: Class weights should be different for each client\n",
        "    freq_pos, freq_neg = compute_class_freqs(all_xray_df.iloc[:,-1])    \n",
        "    pos_weights = freq_neg\n",
        "    neg_weights = freq_pos\n",
        "\n",
        "    valid_loss_min = np.Inf\n",
        "    optimizer = torch.optim.Adam(\n",
        "        net.parameters(),\n",
        "        lr = 1e-4\n",
        "        )\n",
        "    start_time = time.time()\n",
        "    for i in range(epochs):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        valid_acc = 0.0 \n",
        "        net.train()\n",
        "        for j, (images, labels) in enumerate(trainloader):\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            ps = net(images)\n",
        "            \n",
        "            loss = weighted_loss(pos_weights, neg_weights, ps, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        avg_train_loss = train_loss / len(trainloader)\n",
        "        print(\"Epoch : {} Train Loss : {:.6f} \".format(i+1,avg_train_loss))\n",
        "    end_time = time.time()\n",
        "    time_delta = end_time - start_time\n",
        "    print('\\n')\n",
        "    print(f'Time to complete local training round: {time_delta}')\n",
        "    print('\\n')\n",
        "\n",
        "def test(net, testloader, pathology_list):\n",
        "    \n",
        "    # ToDo: Class weights should be different for each client\n",
        "    freq_pos, freq_neg = compute_class_freqs(all_xray_df.iloc[:,-1])    \n",
        "    pos_weights = freq_neg\n",
        "    neg_weights = freq_pos\n",
        "\n",
        "    per_class_accuracy = [0 for i in range(len(pathology_list))]\n",
        "    total = 0.0\n",
        "    loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images,labels in testloader:\n",
        "            ps = net(images.to(DEVICE))\n",
        "            labels = labels.to(DEVICE)\n",
        "            loss += weighted_loss( pos_weights, neg_weights, ps, labels)\n",
        "            ps = (ps >= 0.5).float()\n",
        "\n",
        "            for i in range(ps.shape[1]):\n",
        "                x1 = ps[:,i:i+1]\n",
        "                x2 = labels[:,i:i+1]\n",
        "                per_class_accuracy[i] += int((x1 == x2).sum())\n",
        "\n",
        "        per_class_accuracy = [(i/len(testloader.dataset)) * 100.0 for i in per_class_accuracy]\n",
        "\n",
        "    return loss, np.mean(per_class_accuracy)\n",
        "\n",
        "def get_acc_data(\n",
        "    class_names,\n",
        "    acc_list\n",
        "    ):\n",
        "    df = pd.DataFrame(list(zip(class_names, acc_list)), columns =['Labels', 'Class Acc.']) \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FfVrX3hA6kqX"
      },
      "outputs": [],
      "source": [
        "def server_eval(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays, \n",
        "    config: Dict[str, fl.common.Scalar]\n",
        "    ):\n",
        "    # ToDo: Class weights should be different for each client\n",
        "    freq_pos, freq_neg = compute_class_freqs(all_xray_df.iloc[:,-1])    \n",
        "    pos_weights = freq_neg\n",
        "    neg_weights = freq_pos\n",
        "\n",
        "    net = init_net().to(DEVICE)\n",
        "\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
        "\n",
        "    per_class_accuracy = [0 for i in range(len(all_labels))]\n",
        "    total = 0.0\n",
        "    loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images,labels in testloader:\n",
        "          \n",
        "            ps = net(images.to(DEVICE))\n",
        "            labels = labels.to(DEVICE)\n",
        "            ps = (ps >= 0.5).float()\n",
        "\n",
        "            loss += weighted_loss( pos_weights, neg_weights, ps, labels)\n",
        "\n",
        "            for i in range(ps.shape[1]):\n",
        "                x1 = ps[:,i:i+1]\n",
        "                x2 = labels[:,i:i+1]\n",
        "                per_class_accuracy[i] += int((x1 == x2).sum())\n",
        "\n",
        "        per_class_accuracy = [(i/len(testloader.dataset))*100.0 for i in per_class_accuracy]\n",
        "\n",
        "    test_df = get_acc_data(all_labels, per_class_accuracy)\n",
        "    print('\\nServer eval')\n",
        "    print(test_df)\n",
        "    print('\\n')\n",
        "\n",
        "    return loss,  {\"mean_class_acc.\": np.mean(per_class_accuracy)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZByeD1upefu"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_net():\n",
        "  net = models.vgg11(\n",
        "    weights=\"IMAGENET1K_V1\"\n",
        "  )\n",
        "  net.classifier[-1] = torch.nn.Linear(\n",
        "      net.classifier[-1].in_features,\n",
        "      len(all_labels)\n",
        "  )\n",
        "  return net\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = init_net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    print(f'Created client: {cid}')\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ],
      "metadata": {
        "id": "S5l-5slg58Nf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esohU8khStKD"
      },
      "source": [
        "### 35 local epochs take approx 15min. on A100 for each client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNEdoe3uSumm",
        "outputId": "2ae3e893-5670-432b-92d5-111917671923"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2022-10-21 14:35:09,457 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO:flower:Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2022-10-21 14:35:12,366 | app.py:179 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 12.0, 'node:172.28.0.2': 1.0, 'object_store_memory': 26778869760.0, 'memory': 53557739520.0}\n",
            "INFO:flower:Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 12.0, 'node:172.28.0.2': 1.0, 'object_store_memory': 26778869760.0, 'memory': 53557739520.0}\n",
            "INFO flower 2022-10-21 14:35:12,372 | server.py:86 | Initializing global parameters\n",
            "INFO:flower:Initializing global parameters\n",
            "INFO flower 2022-10-21 14:35:12,374 | server.py:266 | Using initial parameters provided by strategy\n",
            "INFO:flower:Using initial parameters provided by strategy\n",
            "INFO flower 2022-10-21 14:35:12,376 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flower:Evaluating initial parameters\n",
            "INFO flower 2022-10-21 14:38:13,794 | server.py:95 | initial parameters (loss, other metrics): tensor(206.9282, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 88.86831021662482}\n",
            "INFO:flower:initial parameters (loss, other metrics): tensor(206.9282, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 88.86831021662482}\n",
            "INFO flower 2022-10-21 14:38:13,801 | server.py:101 | FL starting\n",
            "INFO:flower:FL starting\n",
            "DEBUG flower 2022-10-21 14:38:13,804 | server.py:220 | fit_round 1: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:fit_round 1: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   87.230248\n",
            "1         Cardiomegaly   92.580703\n",
            "2        Consolidation   67.522739\n",
            "3                Edema   97.806314\n",
            "4             Effusion   83.966470\n",
            "5            Emphysema   97.663635\n",
            "6             Fibrosis   95.987159\n",
            "7         Infiltration   68.450152\n",
            "8                 Mass   94.774389\n",
            "9               Nodule   85.000892\n",
            "10  Pleural_Thickening   96.201177\n",
            "11           Pneumonia   98.626717\n",
            "12        Pneumothorax   89.477439\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Created client: 98\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m [Client 98, round 1] fit, config: {'server_round': 1, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 1 Train Loss : 0.871138 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 2 Train Loss : 0.834317 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 3 Train Loss : 0.830534 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 4 Train Loss : 0.782986 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 5 Train Loss : 0.773493 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 6 Train Loss : 0.748494 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 7 Train Loss : 0.729694 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 8 Train Loss : 0.705475 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 9 Train Loss : 0.671950 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 10 Train Loss : 0.646032 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 11 Train Loss : 0.618663 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 12 Train Loss : 0.580265 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 13 Train Loss : 0.536417 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 14 Train Loss : 0.522160 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 15 Train Loss : 0.513481 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 16 Train Loss : 0.458614 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 17 Train Loss : 0.425754 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 18 Train Loss : 0.395945 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 19 Train Loss : 0.350115 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 20 Train Loss : 0.323218 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 21 Train Loss : 0.295631 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 22 Train Loss : 0.274247 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 23 Train Loss : 0.229158 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 24 Train Loss : 0.237209 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 25 Train Loss : 0.188117 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 26 Train Loss : 0.188160 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 27 Train Loss : 0.158365 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 28 Train Loss : 0.188723 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 29 Train Loss : 0.151177 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 30 Train Loss : 0.120235 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 31 Train Loss : 0.108617 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 32 Train Loss : 0.082291 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 33 Train Loss : 0.114122 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 34 Train Loss : 0.124933 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Epoch : 35 Train Loss : 0.127725 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m Time to complete local training round: 948.4377808570862\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2109)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Created client: 25\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m [Client 25, round 1] fit, config: {'server_round': 1, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 1 Train Loss : 0.936484 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 2 Train Loss : 0.886008 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 3 Train Loss : 0.862259 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 4 Train Loss : 0.834434 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 5 Train Loss : 0.763295 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 6 Train Loss : 0.743753 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 7 Train Loss : 0.714019 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 8 Train Loss : 0.649616 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 9 Train Loss : 0.599410 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 10 Train Loss : 0.528621 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 11 Train Loss : 0.486712 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 12 Train Loss : 0.457030 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 13 Train Loss : 0.401346 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 14 Train Loss : 0.341089 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 15 Train Loss : 0.334773 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 16 Train Loss : 0.254679 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 17 Train Loss : 0.236856 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 18 Train Loss : 0.219814 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 19 Train Loss : 0.210767 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 20 Train Loss : 0.182957 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 21 Train Loss : 0.162576 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 22 Train Loss : 0.116561 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 23 Train Loss : 0.129699 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 24 Train Loss : 0.122445 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 25 Train Loss : 0.125661 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 26 Train Loss : 0.082297 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 27 Train Loss : 0.080130 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 28 Train Loss : 0.097361 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 29 Train Loss : 0.066882 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 30 Train Loss : 0.051613 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 31 Train Loss : 0.061241 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 32 Train Loss : 0.085580 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 33 Train Loss : 0.085140 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 34 Train Loss : 0.064075 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Epoch : 35 Train Loss : 0.081765 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m Time to complete local training round: 947.0500936508179\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2468)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Created client: 6\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m [Client 6, round 1] fit, config: {'server_round': 1, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 1 Train Loss : 0.901636 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 2 Train Loss : 0.885388 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 3 Train Loss : 0.871788 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 4 Train Loss : 0.857626 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 5 Train Loss : 0.825986 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 6 Train Loss : 0.811222 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 7 Train Loss : 0.785073 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 8 Train Loss : 0.739456 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 9 Train Loss : 0.709706 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 10 Train Loss : 0.655969 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 11 Train Loss : 0.643155 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 12 Train Loss : 0.587106 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 13 Train Loss : 0.553308 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 14 Train Loss : 0.469981 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 15 Train Loss : 0.426121 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 16 Train Loss : 0.404738 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 17 Train Loss : 0.388628 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 18 Train Loss : 0.309518 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 19 Train Loss : 0.284952 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 20 Train Loss : 0.263872 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 21 Train Loss : 0.211327 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 22 Train Loss : 0.178764 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 23 Train Loss : 0.195186 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 24 Train Loss : 0.166421 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 25 Train Loss : 0.161917 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 26 Train Loss : 0.125324 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 27 Train Loss : 0.104567 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 28 Train Loss : 0.104564 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 29 Train Loss : 0.114126 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 30 Train Loss : 0.100170 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 31 Train Loss : 0.096973 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 32 Train Loss : 0.067203 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 33 Train Loss : 0.056377 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 34 Train Loss : 0.052490 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Epoch : 35 Train Loss : 0.046878 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m Time to complete local training round: 973.0993037223816\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2791)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Created client: 62\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m [Client 62, round 1] fit, config: {'server_round': 1, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 1 Train Loss : 0.879788 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 2 Train Loss : 0.857907 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 3 Train Loss : 0.849296 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 4 Train Loss : 0.831030 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 5 Train Loss : 0.804057 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 6 Train Loss : 0.806839 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 7 Train Loss : 0.771522 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 8 Train Loss : 0.740170 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 9 Train Loss : 0.722072 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 10 Train Loss : 0.706976 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 11 Train Loss : 0.660456 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 12 Train Loss : 0.627714 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 13 Train Loss : 0.586962 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 14 Train Loss : 0.540617 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 15 Train Loss : 0.498385 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 16 Train Loss : 0.461066 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 17 Train Loss : 0.409629 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 18 Train Loss : 0.391767 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 19 Train Loss : 0.388492 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 20 Train Loss : 0.337958 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 21 Train Loss : 0.259367 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 22 Train Loss : 0.258957 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 23 Train Loss : 0.210343 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 24 Train Loss : 0.216846 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 25 Train Loss : 0.171710 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 26 Train Loss : 0.158169 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 27 Train Loss : 0.170738 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 28 Train Loss : 0.109730 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 29 Train Loss : 0.120073 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 30 Train Loss : 0.125570 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 31 Train Loss : 0.095164 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 32 Train Loss : 0.102425 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 33 Train Loss : 0.075530 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 34 Train Loss : 0.101688 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Epoch : 35 Train Loss : 0.088987 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m Time to complete local training round: 991.3293821811676\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3119)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Created client: 44\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m [Client 44, round 1] fit, config: {'server_round': 1, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 1 Train Loss : 0.895633 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 2 Train Loss : 0.882519 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 3 Train Loss : 0.858162 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 4 Train Loss : 0.823843 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 5 Train Loss : 0.823468 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 6 Train Loss : 0.782329 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 7 Train Loss : 0.759095 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 8 Train Loss : 0.728734 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 9 Train Loss : 0.715212 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 10 Train Loss : 0.707874 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 11 Train Loss : 0.657044 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 12 Train Loss : 0.614835 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 13 Train Loss : 0.599485 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 14 Train Loss : 0.581872 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 15 Train Loss : 0.517960 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 16 Train Loss : 0.520075 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 17 Train Loss : 0.501651 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 18 Train Loss : 0.486570 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 19 Train Loss : 0.390675 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 20 Train Loss : 0.362011 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 21 Train Loss : 0.290128 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 22 Train Loss : 0.315475 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 23 Train Loss : 0.259110 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 24 Train Loss : 0.218827 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 25 Train Loss : 0.221265 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 26 Train Loss : 0.186041 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 27 Train Loss : 0.166934 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 28 Train Loss : 0.119429 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 29 Train Loss : 0.165236 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 30 Train Loss : 0.172788 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 31 Train Loss : 0.160790 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 32 Train Loss : 0.130812 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 33 Train Loss : 0.138451 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 34 Train Loss : 0.098420 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Epoch : 35 Train Loss : 0.082611 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m Time to complete local training round: 999.2709286212921\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3443)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2022-10-21 16:00:10,351 | server.py:234 | fit_round 1 received 5 results and 0 failures\n",
            "DEBUG:flower:fit_round 1 received 5 results and 0 failures\n",
            "WARNING flower 2022-10-21 16:00:18,128 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flower:No fit_metrics_aggregation_fn provided\n",
            "INFO flower 2022-10-21 16:03:13,229 | server.py:122 | fit progress: (1, tensor(204.1028, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 94.40122923268989}, 5099.425777244)\n",
            "INFO:flower:fit progress: (1, tensor(204.1028, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 94.40122923268989}, 5099.425777244)\n",
            "DEBUG flower 2022-10-21 16:03:13,236 | server.py:170 | evaluate_round 1: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:evaluate_round 1: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   89.709292\n",
            "1         Cardiomegaly   97.610130\n",
            "2        Consolidation   95.915820\n",
            "3                Edema   97.877653\n",
            "4             Effusion   88.318174\n",
            "5            Emphysema   97.681470\n",
            "6             Fibrosis   98.519708\n",
            "7         Infiltration   81.558766\n",
            "8                 Mass   95.059747\n",
            "9               Nodule   94.596041\n",
            "10  Pleural_Thickening   97.003745\n",
            "11           Pneumonia   98.626717\n",
            "12        Pneumothorax   94.738719\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[1m\u001b[36m(scheduler +1h30m24s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h30m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2022-10-21 16:03:43,431 | server.py:184 | evaluate_round 1 received 0 results and 5 failures\n",
            "DEBUG:flower:evaluate_round 1 received 0 results and 5 failures\n",
            "DEBUG flower 2022-10-21 16:03:43,433 | server.py:220 | fit_round 2: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:fit_round 2: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Created client: 80\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m [Client 80, round 2] fit, config: {'server_round': 2, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 1 Train Loss : 0.875409 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 2 Train Loss : 0.795529 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 3 Train Loss : 0.788819 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 4 Train Loss : 0.748520 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 5 Train Loss : 0.696139 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 6 Train Loss : 0.639979 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 7 Train Loss : 0.593584 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 8 Train Loss : 0.543762 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 9 Train Loss : 0.482005 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 10 Train Loss : 0.460512 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 11 Train Loss : 0.404079 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 12 Train Loss : 0.383754 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 13 Train Loss : 0.372623 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 14 Train Loss : 0.299172 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 15 Train Loss : 0.314530 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 16 Train Loss : 0.231559 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 17 Train Loss : 0.261877 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 18 Train Loss : 0.209059 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 19 Train Loss : 0.149266 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 20 Train Loss : 0.151687 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 21 Train Loss : 0.147694 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 22 Train Loss : 0.121401 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 23 Train Loss : 0.116065 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 24 Train Loss : 0.091794 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 25 Train Loss : 0.089419 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 26 Train Loss : 0.119331 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 27 Train Loss : 0.083228 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 28 Train Loss : 0.075296 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 29 Train Loss : 0.061524 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 30 Train Loss : 0.054472 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 31 Train Loss : 0.072218 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 32 Train Loss : 0.095021 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 33 Train Loss : 0.082033 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 34 Train Loss : 0.056563 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Epoch : 35 Train Loss : 0.059102 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m Time to complete local training round: 912.1538319587708\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4310)\u001b[0m \n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h46m16s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Created client: 34\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m [Client 34, round 2] fit, config: {'server_round': 2, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 1 Train Loss : 0.854252 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 2 Train Loss : 0.788006 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 3 Train Loss : 0.746243 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 4 Train Loss : 0.706893 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 5 Train Loss : 0.650337 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 6 Train Loss : 0.612858 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 7 Train Loss : 0.529951 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 8 Train Loss : 0.507655 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 9 Train Loss : 0.477210 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 10 Train Loss : 0.411265 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 11 Train Loss : 0.348902 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 12 Train Loss : 0.310770 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 13 Train Loss : 0.284072 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 14 Train Loss : 0.284702 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 15 Train Loss : 0.224451 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 16 Train Loss : 0.186394 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 17 Train Loss : 0.156977 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 18 Train Loss : 0.181589 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 19 Train Loss : 0.161408 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 20 Train Loss : 0.110290 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 21 Train Loss : 0.146118 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 22 Train Loss : 0.181099 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 23 Train Loss : 0.147127 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 24 Train Loss : 0.111981 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 25 Train Loss : 0.139618 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 26 Train Loss : 0.123629 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 27 Train Loss : 0.085264 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 28 Train Loss : 0.086709 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 29 Train Loss : 0.078516 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 30 Train Loss : 0.077389 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 31 Train Loss : 0.045214 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 32 Train Loss : 0.034718 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 33 Train Loss : 0.056068 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 34 Train Loss : 0.095965 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Epoch : 35 Train Loss : 0.106071 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m Time to complete local training round: 920.8839330673218\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4612)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Created client: 78\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m [Client 78, round 2] fit, config: {'server_round': 2, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 1 Train Loss : 0.896511 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 2 Train Loss : 0.838456 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 3 Train Loss : 0.807351 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 4 Train Loss : 0.771100 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 5 Train Loss : 0.709523 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 6 Train Loss : 0.672337 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 7 Train Loss : 0.638449 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 8 Train Loss : 0.580416 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 9 Train Loss : 0.552487 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 10 Train Loss : 0.478904 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 11 Train Loss : 0.471077 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 12 Train Loss : 0.426454 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 13 Train Loss : 0.394139 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 14 Train Loss : 0.318659 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 15 Train Loss : 0.277500 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 16 Train Loss : 0.248770 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 17 Train Loss : 0.243626 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 18 Train Loss : 0.246483 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 19 Train Loss : 0.216097 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 20 Train Loss : 0.200921 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 21 Train Loss : 0.186056 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 22 Train Loss : 0.157627 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 23 Train Loss : 0.121654 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 24 Train Loss : 0.168034 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 25 Train Loss : 0.107840 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 26 Train Loss : 0.099247 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 27 Train Loss : 0.082121 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 28 Train Loss : 0.092661 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 29 Train Loss : 0.075373 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 30 Train Loss : 0.064145 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 31 Train Loss : 0.115223 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 32 Train Loss : 0.123779 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 33 Train Loss : 0.101629 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 34 Train Loss : 0.071455 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Epoch : 35 Train Loss : 0.091703 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m Time to complete local training round: 921.6230471134186\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4924)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2022-10-21 16:50:22,278 | server.py:234 | fit_round 2 received 3 results and 2 failures\n",
            "DEBUG:flower:fit_round 2 received 3 results and 2 failures\n",
            "INFO flower 2022-10-21 16:53:09,783 | server.py:122 | fit progress: (2, tensor(201.7490, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 74.73213428269608}, 8095.979252888001)\n",
            "INFO:flower:fit progress: (2, tensor(201.7490, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 74.73213428269608}, 8095.979252888001)\n",
            "DEBUG flower 2022-10-21 16:53:09,789 | server.py:170 | evaluate_round 2: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:evaluate_round 2: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   80.934546\n",
            "1         Cardiomegaly   93.739968\n",
            "2        Consolidation   62.796504\n",
            "3                Edema   95.487783\n",
            "4             Effusion   86.570358\n",
            "5            Emphysema   32.548600\n",
            "6             Fibrosis   61.458891\n",
            "7         Infiltration   71.392902\n",
            "8                 Mass   91.635456\n",
            "9               Nodule   81.202069\n",
            "10  Pleural_Thickening   77.742108\n",
            "11           Pneumonia   63.706082\n",
            "12        Pneumothorax   72.302479\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5358)\u001b[0m Created client: 46\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5358)\u001b[0m [Client 46] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5444)\u001b[0m Created client: 77\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5444)\u001b[0m [Client 77] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5479)\u001b[0m Created client: 28\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5479)\u001b[0m [Client 28] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5514)\u001b[0m Created client: 21\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5514)\u001b[0m [Client 21] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5549)\u001b[0m Created client: 92\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2022-10-21 16:53:49,288 | server.py:184 | evaluate_round 2 received 0 results and 5 failures\n",
            "DEBUG:flower:evaluate_round 2 received 0 results and 5 failures\n",
            "DEBUG flower 2022-10-21 16:53:49,292 | server.py:220 | fit_round 3: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:fit_round 3: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5549)\u001b[0m [Client 92] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Created client: 7\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m [Client 7, round 3] fit, config: {'server_round': 3, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 1 Train Loss : 0.850380 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 2 Train Loss : 0.755872 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 3 Train Loss : 0.688319 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 4 Train Loss : 0.616137 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 5 Train Loss : 0.595296 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 6 Train Loss : 0.545060 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 7 Train Loss : 0.467266 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 8 Train Loss : 0.422285 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 9 Train Loss : 0.419451 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 10 Train Loss : 0.344874 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 11 Train Loss : 0.303304 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 12 Train Loss : 0.248263 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 13 Train Loss : 0.253134 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 14 Train Loss : 0.205157 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 15 Train Loss : 0.222219 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 16 Train Loss : 0.159553 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 17 Train Loss : 0.131504 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 18 Train Loss : 0.177401 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 19 Train Loss : 0.138863 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 20 Train Loss : 0.107264 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 21 Train Loss : 0.113717 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 22 Train Loss : 0.111284 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 23 Train Loss : 0.075843 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 24 Train Loss : 0.093746 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 25 Train Loss : 0.095403 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 26 Train Loss : 0.066638 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 27 Train Loss : 0.050240 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 28 Train Loss : 0.079211 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 29 Train Loss : 0.078048 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 30 Train Loss : 0.059712 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 31 Train Loss : 0.094306 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 32 Train Loss : 0.098584 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 33 Train Loss : 0.073193 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 34 Train Loss : 0.049928 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Epoch : 35 Train Loss : 0.044919 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m Time to complete local training round: 922.3979046344757\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5679)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Created client: 53\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m [Client 53, round 3] fit, config: {'server_round': 3, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 1 Train Loss : 0.898960 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 2 Train Loss : 0.780501 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 3 Train Loss : 0.704928 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 4 Train Loss : 0.662553 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 5 Train Loss : 0.626757 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 6 Train Loss : 0.553112 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 7 Train Loss : 0.489734 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 8 Train Loss : 0.456072 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 9 Train Loss : 0.403764 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 10 Train Loss : 0.356432 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 11 Train Loss : 0.345051 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 12 Train Loss : 0.275679 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 13 Train Loss : 0.278708 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 14 Train Loss : 0.259268 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 15 Train Loss : 0.200726 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 16 Train Loss : 0.197732 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 17 Train Loss : 0.200588 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 18 Train Loss : 0.147854 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 19 Train Loss : 0.183436 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 20 Train Loss : 0.118616 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 21 Train Loss : 0.131022 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 22 Train Loss : 0.143175 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 23 Train Loss : 0.134515 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 24 Train Loss : 0.086394 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 25 Train Loss : 0.127343 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 26 Train Loss : 0.097233 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 27 Train Loss : 0.110058 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 28 Train Loss : 0.076234 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 29 Train Loss : 0.054605 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 30 Train Loss : 0.063947 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 31 Train Loss : 0.073795 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 32 Train Loss : 0.068924 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 33 Train Loss : 0.073039 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 34 Train Loss : 0.093300 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Epoch : 35 Train Loss : 0.104580 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m Time to complete local training round: 944.7767107486725\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6115)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2022-10-21 17:25:37,296 | server.py:234 | fit_round 3 received 2 results and 3 failures\n",
            "DEBUG:flower:fit_round 3 received 2 results and 3 failures\n",
            "INFO flower 2022-10-21 17:28:29,511 | server.py:122 | fit progress: (3, tensor(203.7360, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 76.75570372199586}, 10215.707277522)\n",
            "INFO:flower:fit progress: (3, tensor(203.7360, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 76.75570372199586}, 10215.707277522)\n",
            "DEBUG flower 2022-10-21 17:28:29,518 | server.py:170 | evaluate_round 3: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:evaluate_round 3: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   79.472088\n",
            "1         Cardiomegaly   92.491528\n",
            "2        Consolidation   41.555199\n",
            "3                Edema   62.635991\n",
            "4             Effusion   86.249331\n",
            "5            Emphysema   53.272695\n",
            "6             Fibrosis   87.854468\n",
            "7         Infiltration   70.911361\n",
            "8                 Mass   92.901730\n",
            "9               Nodule   94.292848\n",
            "10  Pleural_Thickening   82.504013\n",
            "11           Pneumonia   64.847512\n",
            "12        Pneumothorax   88.835384\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6615)\u001b[0m Created client: 90\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6615)\u001b[0m [Client 90] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6650)\u001b[0m Created client: 89\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6650)\u001b[0m [Client 89] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6687)\u001b[0m Created client: 59\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6687)\u001b[0m [Client 59] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6724)\u001b[0m Created client: 61\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6724)\u001b[0m [Client 61] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6759)\u001b[0m Created client: 46\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2022-10-21 17:29:11,718 | server.py:184 | evaluate_round 3 received 0 results and 5 failures\n",
            "DEBUG:flower:evaluate_round 3 received 0 results and 5 failures\n",
            "DEBUG flower 2022-10-21 17:29:11,723 | server.py:220 | fit_round 4: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:fit_round 4: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6759)\u001b[0m [Client 46] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Created client: 64\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m [Client 64, round 4] fit, config: {'server_round': 4, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 1 Train Loss : 0.881114 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 2 Train Loss : 0.748385 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 3 Train Loss : 0.660859 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 4 Train Loss : 0.619090 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 5 Train Loss : 0.554530 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 6 Train Loss : 0.523645 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 7 Train Loss : 0.450298 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 8 Train Loss : 0.392610 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 9 Train Loss : 0.351351 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 10 Train Loss : 0.295052 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 11 Train Loss : 0.258434 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 12 Train Loss : 0.234228 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 13 Train Loss : 0.217668 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 14 Train Loss : 0.220107 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 15 Train Loss : 0.148929 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 16 Train Loss : 0.161707 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 17 Train Loss : 0.184195 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 18 Train Loss : 0.198599 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 19 Train Loss : 0.159932 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 20 Train Loss : 0.091076 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 21 Train Loss : 0.093439 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 22 Train Loss : 0.118591 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 23 Train Loss : 0.109338 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 24 Train Loss : 0.113771 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 25 Train Loss : 0.083855 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 26 Train Loss : 0.067706 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 27 Train Loss : 0.087579 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 28 Train Loss : 0.082078 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 29 Train Loss : 0.119304 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 30 Train Loss : 0.135896 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 31 Train Loss : 0.073177 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 32 Train Loss : 0.062705 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 33 Train Loss : 0.055395 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 34 Train Loss : 0.066292 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Epoch : 35 Train Loss : 0.059224 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m Time to complete local training round: 940.6937124729156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6825)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Created client: 68\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m [Client 68, round 4] fit, config: {'server_round': 4, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 1 Train Loss : 0.971865 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 2 Train Loss : 0.790230 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 3 Train Loss : 0.695893 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 4 Train Loss : 0.644584 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 5 Train Loss : 0.551971 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 6 Train Loss : 0.526456 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 7 Train Loss : 0.492556 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 8 Train Loss : 0.521348 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 9 Train Loss : 0.366241 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 10 Train Loss : 0.341286 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 11 Train Loss : 0.321660 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 12 Train Loss : 0.281971 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 13 Train Loss : 0.318832 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 14 Train Loss : 0.233494 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 15 Train Loss : 0.236093 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 16 Train Loss : 0.205279 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 17 Train Loss : 0.226003 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 18 Train Loss : 0.172469 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 19 Train Loss : 0.161614 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 20 Train Loss : 0.167126 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 21 Train Loss : 0.165464 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 22 Train Loss : 0.139879 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 23 Train Loss : 0.144369 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 24 Train Loss : 0.122447 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 25 Train Loss : 0.127866 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 26 Train Loss : 0.099032 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 27 Train Loss : 0.089629 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 28 Train Loss : 0.099321 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 29 Train Loss : 0.058626 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 30 Train Loss : 0.066981 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 31 Train Loss : 0.049194 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 32 Train Loss : 0.068293 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 33 Train Loss : 0.073293 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 34 Train Loss : 0.063691 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Epoch : 35 Train Loss : 0.070213 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Time to complete local training round: 950.6491622924805\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Created client: 92\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m [Client 92, round 4] fit, config: {'server_round': 4, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 1 Train Loss : 0.962193 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 2 Train Loss : 0.786874 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 3 Train Loss : 0.716934 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 4 Train Loss : 0.628694 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 5 Train Loss : 0.577920 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 6 Train Loss : 0.530276 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 7 Train Loss : 0.477061 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 8 Train Loss : 0.389181 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 9 Train Loss : 0.388899 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 10 Train Loss : 0.372860 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 11 Train Loss : 0.387692 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 12 Train Loss : 0.291495 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 13 Train Loss : 0.240942 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 14 Train Loss : 0.273066 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 15 Train Loss : 0.238563 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 16 Train Loss : 0.165344 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 17 Train Loss : 0.196075 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 18 Train Loss : 0.164118 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 19 Train Loss : 0.167952 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 20 Train Loss : 0.130282 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 21 Train Loss : 0.161730 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 22 Train Loss : 0.151962 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 23 Train Loss : 0.122180 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 24 Train Loss : 0.123129 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 25 Train Loss : 0.136231 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 26 Train Loss : 0.133970 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 27 Train Loss : 0.121874 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 28 Train Loss : 0.083051 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 29 Train Loss : 0.080965 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 30 Train Loss : 0.076447 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 31 Train Loss : 0.071183 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 32 Train Loss : 0.092181 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 33 Train Loss : 0.080211 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 34 Train Loss : 0.065360 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Epoch : 35 Train Loss : 0.043670 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m Time to complete local training round: 947.4895236492157\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7539)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-21 18:17:14,563 | server.py:234 | fit_round 4 received 3 results and 2 failures\n",
            "DEBUG:flower:fit_round 4 received 3 results and 2 failures\n",
            "INFO flower 2022-10-21 18:20:07,926 | server.py:122 | fit progress: (4, tensor(202.5287, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 77.32779081093688}, 13314.122095123)\n",
            "INFO:flower:fit progress: (4, tensor(202.5287, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 77.32779081093688}, 13314.122095123)\n",
            "DEBUG flower 2022-10-21 18:20:07,931 | server.py:170 | evaluate_round 4: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:evaluate_round 4: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   79.917960\n",
            "1         Cardiomegaly   96.968076\n",
            "2        Consolidation   85.999643\n",
            "3                Edema   67.433565\n",
            "4             Effusion   87.979312\n",
            "5            Emphysema   56.911004\n",
            "6             Fibrosis   74.514000\n",
            "7         Infiltration   74.496166\n",
            "8                 Mass   89.709292\n",
            "9               Nodule   92.794721\n",
            "10  Pleural_Thickening   80.381666\n",
            "11           Pneumonia   34.456929\n",
            "12        Pneumothorax   83.698948\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8098)\u001b[0m Created client: 79\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8098)\u001b[0m [Client 79] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8134)\u001b[0m Created client: 38\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8134)\u001b[0m [Client 38] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8169)\u001b[0m Created client: 93\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8169)\u001b[0m [Client 93] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8204)\u001b[0m Created client: 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-21 18:20:45,115 | server.py:184 | evaluate_round 4 received 0 results and 5 failures\n",
            "DEBUG:flower:evaluate_round 4 received 0 results and 5 failures\n",
            "DEBUG flower 2022-10-21 18:20:45,120 | server.py:220 | fit_round 5: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:fit_round 5: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8204)\u001b[0m [Client 34] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Created client: 52\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m [Client 52, round 5] fit, config: {'server_round': 5, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 1 Train Loss : 0.930622 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 2 Train Loss : 0.762377 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 3 Train Loss : 0.683026 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 4 Train Loss : 0.600600 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 5 Train Loss : 0.542959 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 6 Train Loss : 0.502190 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 7 Train Loss : 0.450535 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 8 Train Loss : 0.418545 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 9 Train Loss : 0.391732 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 10 Train Loss : 0.339191 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 11 Train Loss : 0.267634 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 12 Train Loss : 0.256971 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 13 Train Loss : 0.261633 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 14 Train Loss : 0.195334 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 15 Train Loss : 0.180214 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 16 Train Loss : 0.213673 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 17 Train Loss : 0.269550 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 18 Train Loss : 0.224777 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 19 Train Loss : 0.134996 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 20 Train Loss : 0.156357 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 21 Train Loss : 0.124241 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 22 Train Loss : 0.108759 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 23 Train Loss : 0.093726 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 24 Train Loss : 0.115351 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 25 Train Loss : 0.108788 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 26 Train Loss : 0.103965 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 27 Train Loss : 0.135073 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 28 Train Loss : 0.185572 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 29 Train Loss : 0.171323 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 30 Train Loss : 0.133686 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 31 Train Loss : 0.093061 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 32 Train Loss : 0.099984 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 33 Train Loss : 0.101165 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 34 Train Loss : 0.089675 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Epoch : 35 Train Loss : 0.069730 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m Time to complete local training round: 956.8626623153687\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8294)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8654)\u001b[0m Created client: 5\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8654)\u001b[0m [Client 5, round 5] fit, config: {'server_round': 5, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8654)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Created client: 23\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m [Client 23, round 5] fit, config: {'server_round': 5, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 1 Train Loss : 0.917589 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 2 Train Loss : 0.720651 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 3 Train Loss : 0.636668 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 4 Train Loss : 0.589680 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 5 Train Loss : 0.515979 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 6 Train Loss : 0.447050 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 7 Train Loss : 0.388959 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 8 Train Loss : 0.355617 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 9 Train Loss : 0.351973 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 10 Train Loss : 0.286029 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 11 Train Loss : 0.276058 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 12 Train Loss : 0.234792 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 13 Train Loss : 0.196831 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 14 Train Loss : 0.207715 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 15 Train Loss : 0.193083 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 16 Train Loss : 0.231682 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 17 Train Loss : 0.183407 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 18 Train Loss : 0.193746 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 19 Train Loss : 0.199539 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 20 Train Loss : 0.169220 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 21 Train Loss : 0.198144 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 22 Train Loss : 0.155377 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 23 Train Loss : 0.130015 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 24 Train Loss : 0.080299 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 25 Train Loss : 0.077664 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 26 Train Loss : 0.089647 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 27 Train Loss : 0.112055 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 28 Train Loss : 0.070796 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 29 Train Loss : 0.071662 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 30 Train Loss : 0.062639 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 31 Train Loss : 0.121425 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 32 Train Loss : 0.112469 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 33 Train Loss : 0.104636 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 34 Train Loss : 0.099555 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Epoch : 35 Train Loss : 0.111882 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m Time to complete local training round: 940.3690896034241\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8690)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Created client: 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m [Client 0, round 5] fit, config: {'server_round': 5, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 1 Train Loss : 0.930841 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 2 Train Loss : 0.737972 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 3 Train Loss : 0.664452 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 4 Train Loss : 0.575879 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 5 Train Loss : 0.521807 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 6 Train Loss : 0.496083 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 7 Train Loss : 0.445060 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 8 Train Loss : 0.423277 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 9 Train Loss : 0.355455 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 10 Train Loss : 0.324517 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 11 Train Loss : 0.277073 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 12 Train Loss : 0.313683 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 13 Train Loss : 0.326379 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 14 Train Loss : 0.324728 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 15 Train Loss : 0.237340 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 16 Train Loss : 0.172639 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 17 Train Loss : 0.173642 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 18 Train Loss : 0.148531 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 19 Train Loss : 0.146126 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 20 Train Loss : 0.099643 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 21 Train Loss : 0.089891 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 22 Train Loss : 0.151943 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 23 Train Loss : 0.113595 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 24 Train Loss : 0.114224 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 25 Train Loss : 0.093233 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 26 Train Loss : 0.109307 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 27 Train Loss : 0.085699 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 28 Train Loss : 0.109425 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 29 Train Loss : 0.086067 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 30 Train Loss : 0.091862 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 31 Train Loss : 0.063250 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 32 Train Loss : 0.125099 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 33 Train Loss : 0.101658 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 34 Train Loss : 0.136704 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Epoch : 35 Train Loss : 0.067582 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m Time to complete local training round: 952.0292320251465\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8972)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Created client: 94\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m [Client 94, round 5] fit, config: {'server_round': 5, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 1 Train Loss : 0.899202 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 2 Train Loss : 0.751090 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 3 Train Loss : 0.679889 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 4 Train Loss : 0.626393 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 5 Train Loss : 0.550114 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 6 Train Loss : 0.499313 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 7 Train Loss : 0.443172 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 8 Train Loss : 0.387745 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 9 Train Loss : 0.395596 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 10 Train Loss : 0.326119 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 11 Train Loss : 0.317256 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 12 Train Loss : 0.301939 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 13 Train Loss : 0.243918 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 14 Train Loss : 0.233957 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 15 Train Loss : 0.189427 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 16 Train Loss : 0.216861 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 17 Train Loss : 0.249475 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 18 Train Loss : 0.178091 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 19 Train Loss : 0.151871 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 20 Train Loss : 0.139253 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 21 Train Loss : 0.125409 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 22 Train Loss : 0.102977 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 23 Train Loss : 0.124333 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 24 Train Loss : 0.153697 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 25 Train Loss : 0.135198 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 26 Train Loss : 0.144314 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 27 Train Loss : 0.136087 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 28 Train Loss : 0.098669 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 29 Train Loss : 0.085534 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 30 Train Loss : 0.098081 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 31 Train Loss : 0.082437 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 32 Train Loss : 0.092213 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 33 Train Loss : 0.112945 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 34 Train Loss : 0.097072 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Epoch : 35 Train Loss : 0.095847 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m Time to complete local training round: 950.7832989692688\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9256)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-21 19:24:59,056 | server.py:234 | fit_round 5 received 4 results and 1 failures\n",
            "DEBUG:flower:fit_round 5 received 4 results and 1 failures\n",
            "INFO flower 2022-10-21 19:27:55,186 | server.py:122 | fit progress: (5, tensor(203.5606, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 72.82380540807506}, 17381.382370312)\n",
            "INFO:flower:fit progress: (5, tensor(203.5606, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 72.82380540807506}, 17381.382370312)\n",
            "DEBUG flower 2022-10-21 19:27:55,193 | server.py:170 | evaluate_round 5: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:evaluate_round 5: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   80.399501\n",
            "1         Cardiomegaly   92.224006\n",
            "2        Consolidation   90.155163\n",
            "3                Edema   66.559658\n",
            "4             Effusion   86.392010\n",
            "5            Emphysema   18.673087\n",
            "6             Fibrosis   77.367576\n",
            "7         Infiltration   80.292492\n",
            "8                 Mass   92.491528\n",
            "9               Nodule   94.007491\n",
            "10  Pleural_Thickening   57.945425\n",
            "11           Pneumonia   18.762261\n",
            "12        Pneumothorax   91.439272\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9812)\u001b[0m Created client: 95\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9812)\u001b[0m [Client 95] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9847)\u001b[0m Created client: 59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-21 19:28:30,207 | server.py:184 | evaluate_round 5 received 0 results and 5 failures\n",
            "DEBUG:flower:evaluate_round 5 received 0 results and 5 failures\n",
            "DEBUG flower 2022-10-21 19:28:30,211 | server.py:220 | fit_round 6: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:fit_round 6: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9847)\u001b[0m [Client 59] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9913)\u001b[0m Created client: 86\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9913)\u001b[0m [Client 86, round 6] fit, config: {'server_round': 6, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9913)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10045)\u001b[0m Created client: 71\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10045)\u001b[0m [Client 71, round 6] fit, config: {'server_round': 6, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10045)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Created client: 26\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m [Client 26, round 6] fit, config: {'server_round': 6, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 1 Train Loss : 0.870468 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 2 Train Loss : 0.733879 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 3 Train Loss : 0.641814 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 4 Train Loss : 0.591246 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 5 Train Loss : 0.516457 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 6 Train Loss : 0.457962 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 7 Train Loss : 0.405480 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 8 Train Loss : 0.371826 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 9 Train Loss : 0.355995 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 10 Train Loss : 0.380629 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 11 Train Loss : 0.273619 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 12 Train Loss : 0.218813 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 13 Train Loss : 0.226945 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 14 Train Loss : 0.231296 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 15 Train Loss : 0.210530 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 16 Train Loss : 0.161490 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 17 Train Loss : 0.168922 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 18 Train Loss : 0.152703 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 19 Train Loss : 0.158937 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 20 Train Loss : 0.141111 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 21 Train Loss : 0.173505 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 22 Train Loss : 0.185112 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 23 Train Loss : 0.151071 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 24 Train Loss : 0.130593 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 25 Train Loss : 0.113292 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 26 Train Loss : 0.063567 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 27 Train Loss : 0.076049 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 28 Train Loss : 0.083611 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 29 Train Loss : 0.105792 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 30 Train Loss : 0.096993 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 31 Train Loss : 0.098660 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 32 Train Loss : 0.090781 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 33 Train Loss : 0.064495 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 34 Train Loss : 0.078581 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Epoch : 35 Train Loss : 0.058575 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m Time to complete local training round: 965.3724994659424\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10082)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10363)\u001b[0m Created client: 39\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10363)\u001b[0m [Client 39, round 6] fit, config: {'server_round': 6, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10363)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Created client: 52\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m [Client 52, round 6] fit, config: {'server_round': 6, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 1 Train Loss : 0.651737 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 2 Train Loss : 0.447185 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 3 Train Loss : 0.323800 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 4 Train Loss : 0.294047 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 5 Train Loss : 0.285683 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 6 Train Loss : 0.228478 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 7 Train Loss : 0.203048 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 8 Train Loss : 0.181278 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 9 Train Loss : 0.173923 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 10 Train Loss : 0.217353 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 11 Train Loss : 0.178690 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 12 Train Loss : 0.141211 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 13 Train Loss : 0.146141 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 14 Train Loss : 0.119278 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 15 Train Loss : 0.087608 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 16 Train Loss : 0.090437 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 17 Train Loss : 0.096658 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 18 Train Loss : 0.184162 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 19 Train Loss : 0.244675 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 20 Train Loss : 0.148825 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 21 Train Loss : 0.132019 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 22 Train Loss : 0.110294 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 23 Train Loss : 0.087936 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 24 Train Loss : 0.053707 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 25 Train Loss : 0.044580 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 26 Train Loss : 0.075672 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 27 Train Loss : 0.086946 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 28 Train Loss : 0.072412 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 29 Train Loss : 0.071334 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 30 Train Loss : 0.056155 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 31 Train Loss : 0.058695 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 32 Train Loss : 0.054625 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 33 Train Loss : 0.069560 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 34 Train Loss : 0.037706 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Epoch : 35 Train Loss : 0.048811 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m Time to complete local training round: 940.734325170517\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10412)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-21 20:01:05,022 | server.py:234 | fit_round 6 received 2 results and 3 failures\n",
            "DEBUG:flower:fit_round 6 received 2 results and 3 failures\n",
            "INFO flower 2022-10-21 20:03:56,392 | server.py:122 | fit progress: (6, tensor(204.0399, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 81.53818715616468}, 19542.588419845)\n",
            "INFO:flower:fit progress: (6, tensor(204.0399, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 81.53818715616468}, 19542.588419845)\n",
            "DEBUG flower 2022-10-21 20:03:56,398 | server.py:170 | evaluate_round 6: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:evaluate_round 6: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   85.518102\n",
            "1         Cardiomegaly   97.449617\n",
            "2        Consolidation   59.907259\n",
            "3                Edema   92.830391\n",
            "4             Effusion   88.104156\n",
            "5            Emphysema   32.191903\n",
            "6             Fibrosis   88.478687\n",
            "7         Infiltration   81.469592\n",
            "8                 Mass   86.784377\n",
            "9               Nodule   94.150169\n",
            "10  Pleural_Thickening   88.282504\n",
            "11           Pneumonia   72.552167\n",
            "12        Pneumothorax   92.277510\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10850)\u001b[0m Created client: 69\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10850)\u001b[0m [Client 69] evaluate, config: {}\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +5h31m6s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10885)\u001b[0m Created client: 12\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10885)\u001b[0m [Client 12] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10920)\u001b[0m Created client: 54\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10920)\u001b[0m [Client 54] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10955)\u001b[0m Created client: 99\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10955)\u001b[0m [Client 99] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10991)\u001b[0m Created client: 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-21 20:04:37,982 | server.py:184 | evaluate_round 6 received 0 results and 5 failures\n",
            "DEBUG:flower:evaluate_round 6 received 0 results and 5 failures\n",
            "DEBUG flower 2022-10-21 20:04:37,986 | server.py:220 | fit_round 7: strategy sampled 5 clients (out of 100)\n",
            "DEBUG:flower:fit_round 7: strategy sampled 5 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10991)\u001b[0m [Client 80] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Created client: 85\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m [Client 85, round 7] fit, config: {'server_round': 7, 'local_epochs': 35}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Entered train function, total num. of epochs: 35\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 1 Train Loss : 1.015137 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 2 Train Loss : 0.772295 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 3 Train Loss : 0.700685 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 4 Train Loss : 0.635635 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 5 Train Loss : 0.589913 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 6 Train Loss : 0.529047 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 7 Train Loss : 0.507417 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 8 Train Loss : 0.459688 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 9 Train Loss : 0.375017 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 10 Train Loss : 0.344846 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 11 Train Loss : 0.318680 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 12 Train Loss : 0.318524 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 13 Train Loss : 0.272770 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 14 Train Loss : 0.274550 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 15 Train Loss : 0.238781 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 16 Train Loss : 0.201478 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11063)\u001b[0m Epoch : 17 Train Loss : 0.222732 \n"
          ]
        }
      ],
      "source": [
        "num_rounds = 10\n",
        "local_epochs = 35\n",
        "fraction_fit = 0.05\n",
        "fraction_evaluate = 0.05\n",
        "min_fit_clients = 5\n",
        "min_evaluate_clients = 5\n",
        "\n",
        "client_resources = {\n",
        "    \"num_cpus\": 1,\n",
        "    \"num_gpus\": 1\n",
        "    }\n",
        "\n",
        "def fit_config(server_round: int):    \n",
        "    config = {\n",
        "        \"server_round\": server_round,\n",
        "        \"local_epochs\": local_epochs,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "# Create an instance of the model and get the parameters\n",
        "net = init_net()\n",
        "params = get_parameters(init_net())\n",
        "\n",
        "# Pass parameters to the Strategy for server-side parameter initialization\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=fraction_fit,\n",
        "    fraction_evaluate=fraction_evaluate,\n",
        "    min_fit_clients=min_fit_clients,\n",
        "    min_evaluate_clients=min_evaluate_clients,\n",
        "    min_available_clients=num_clients,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    evaluate_fn=server_eval,\n",
        "    on_fit_config_fn=fit_config,\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=num_clients,\n",
        "    client_resources=client_resources,\n",
        "    config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "    strategy=strategy,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBYaiOGnS3f9"
      },
      "source": [
        "### 2 local epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEYaEENLS46x",
        "outputId": "da4b4a1f-ecd4-43f4-d994-084a97aaa3dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2022-10-20 12:26:33,666 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)\n",
            "INFO:flower:Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)\n",
            "INFO flower 2022-10-20 12:26:39,088 | app.py:179 | Flower VCE: Ray initialized with resources: {'node:172.28.0.2': 1.0, 'object_store_memory': 26786764800.0, 'memory': 53573529600.0, 'GPU': 1.0, 'CPU': 12.0}\n",
            "INFO:flower:Flower VCE: Ray initialized with resources: {'node:172.28.0.2': 1.0, 'object_store_memory': 26786764800.0, 'memory': 53573529600.0, 'GPU': 1.0, 'CPU': 12.0}\n",
            "INFO flower 2022-10-20 12:26:39,091 | server.py:86 | Initializing global parameters\n",
            "INFO:flower:Initializing global parameters\n",
            "INFO flower 2022-10-20 12:26:39,096 | server.py:266 | Using initial parameters provided by strategy\n",
            "INFO:flower:Using initial parameters provided by strategy\n",
            "INFO flower 2022-10-20 12:26:39,099 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flower:Evaluating initial parameters\n",
            "INFO flower 2022-10-20 12:29:29,539 | server.py:95 | initial parameters (loss, other metrics): tensor(208.0653, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 90.03031924380238}\n",
            "INFO:flower:initial parameters (loss, other metrics): tensor(208.0653, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 90.03031924380238}\n",
            "INFO flower 2022-10-20 12:29:29,545 | server.py:101 | FL starting\n",
            "INFO:flower:FL starting\n",
            "DEBUG flower 2022-10-20 12:29:29,549 | server.py:220 | fit_round 1: strategy sampled 1 clients (out of 10)\n",
            "DEBUG:flower:fit_round 1: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   86.017478\n",
            "1         Cardiomegaly   95.969324\n",
            "2        Consolidation   90.137328\n",
            "3                Edema   89.637953\n",
            "4             Effusion   85.428928\n",
            "5            Emphysema   97.717139\n",
            "6             Fibrosis   98.430533\n",
            "7         Infiltration   60.246121\n",
            "8                 Mass   91.706795\n",
            "9               Nodule   91.760300\n",
            "10  Pleural_Thickening   94.239344\n",
            "11           Pneumonia   94.845729\n",
            "12        Pneumothorax   94.257179\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Created client: 6\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m [Client 6, round 1] fit, config: {'server_round': 1, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Entered train function, total num. of epochs: 2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Iteration 0, loss: 0.9309484082780329\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Iteration 100, loss: 0.8324902877098763\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Iteration 200, loss: 0.8417237977649786\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Iteration 300, loss: 0.6053079236463453\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Epoch : 1 Train Loss : 0.848716 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Iteration 0, loss: 0.8063397330788153\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Iteration 100, loss: 0.8544451006233814\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Iteration 200, loss: 0.6035737316617997\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Iteration 300, loss: 0.6616941983594188\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Epoch : 2 Train Loss : 0.796369 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m Time to complete local training round: 534.1247878074646\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12888)\u001b[0m \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2022-10-20 12:38:35,539 | server.py:234 | fit_round 1 received 1 results and 0 failures\n",
            "DEBUG:flower:fit_round 1 received 1 results and 0 failures\n",
            "WARNING flower 2022-10-20 12:38:37,080 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flower:No fit_metrics_aggregation_fn provided\n",
            "INFO flower 2022-10-20 12:41:26,336 | server.py:122 | fit progress: (1, tensor(202.5730, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 92.39961037713846}, 716.7872724610006)\n",
            "INFO:flower:fit progress: (1, tensor(202.5730, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 92.39961037713846}, 716.7872724610006)\n",
            "DEBUG flower 2022-10-20 12:41:26,343 | server.py:170 | evaluate_round 1: strategy sampled 1 clients (out of 10)\n",
            "DEBUG:flower:evaluate_round 1: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   89.530943\n",
            "1         Cardiomegaly   96.379526\n",
            "2        Consolidation   87.034065\n",
            "3                Edema   87.479936\n",
            "4             Effusion   87.997146\n",
            "5            Emphysema   97.467451\n",
            "6             Fibrosis   98.537542\n",
            "7         Infiltration   78.259319\n",
            "8                 Mass   94.756554\n",
            "9               Nodule   93.044409\n",
            "10  Pleural_Thickening   96.843232\n",
            "11           Pneumonia   98.822900\n",
            "12        Pneumothorax   95.041912\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13140)\u001b[0m Created client: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2022-10-20 12:41:34,748 | server.py:184 | evaluate_round 1 received 0 results and 1 failures\n",
            "DEBUG:flower:evaluate_round 1 received 0 results and 1 failures\n",
            "INFO flower 2022-10-20 12:41:34,751 | server.py:144 | FL finished in 725.2018406299994\n",
            "INFO:flower:FL finished in 725.2018406299994\n",
            "INFO flower 2022-10-20 12:41:34,765 | app.py:180 | app_fit: losses_distributed []\n",
            "INFO:flower:app_fit: losses_distributed []\n",
            "INFO flower 2022-10-20 12:41:34,767 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO:flower:app_fit: metrics_distributed {}\n",
            "INFO flower 2022-10-20 12:41:34,775 | app.py:182 | app_fit: losses_centralized [(0, tensor(208.0653, device='cuda:0', dtype=torch.float64)), (1, tensor(202.5730, device='cuda:0', dtype=torch.float64))]\n",
            "INFO:flower:app_fit: losses_centralized [(0, tensor(208.0653, device='cuda:0', dtype=torch.float64)), (1, tensor(202.5730, device='cuda:0', dtype=torch.float64))]\n",
            "INFO flower 2022-10-20 12:41:34,777 | app.py:183 | app_fit: metrics_centralized {'mean_class_acc.': [(0, 90.03031924380238), (1, 92.39961037713846)]}\n",
            "INFO:flower:app_fit: metrics_centralized {'mean_class_acc.': [(0, 90.03031924380238), (1, 92.39961037713846)]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13140)\u001b[0m [Client 7] evaluate, config: {}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "History (loss, centralized):\n",
              "\tround 0: 208.06525430734155\n",
              "\tround 1: 202.57301380878866\n",
              "History (metrics, centralized):\n",
              "{'mean_class_acc.': [(0, 90.03031924380238), (1, 92.39961037713846)]}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_rounds = 1\n",
        "local_epochs = 2\n",
        "fraction_fit = 0.1\n",
        "fraction_evaluate = 0.1\n",
        "min_fit_clients = 1\n",
        "min_evaluate_clients = 1\n",
        "\n",
        "client_resources = {\n",
        "    \"num_cpus\": 1,\n",
        "    \"num_gpus\": 1\n",
        "    }\n",
        "\n",
        "def fit_config(server_round: int):    \n",
        "    config = {\n",
        "        \"server_round\": server_round,\n",
        "        \"local_epochs\": local_epochs,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "# Create an instance of the model and get the parameters\n",
        "net = init_net()\n",
        "params = get_parameters(init_net())\n",
        "\n",
        "# Pass parameters to the Strategy for server-side parameter initialization\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=fraction_fit,\n",
        "    fraction_evaluate=fraction_evaluate,\n",
        "    min_fit_clients=min_fit_clients,\n",
        "    min_evaluate_clients=min_evaluate_clients,\n",
        "    min_available_clients=num_clients,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    evaluate_fn=server_eval,\n",
        "    on_fit_config_fn=fit_config,\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=num_clients,\n",
        "    client_resources=client_resources,\n",
        "    config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "    strategy=strategy,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eScoLyy4_8Ps"
      },
      "source": [
        "### 5 local epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AOlDvhXBUYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de3f177-6d52-4a0f-c1be-c0c4da884510"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2022-10-20 12:41:38,040 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)\n",
            "INFO:flower:Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)\n",
            "INFO flower 2022-10-20 12:41:43,835 | app.py:179 | Flower VCE: Ray initialized with resources: {'memory': 53587621479.0, 'node:172.28.0.2': 1.0, 'CPU': 12.0, 'GPU': 1.0, 'object_store_memory': 26793810739.0}\n",
            "INFO:flower:Flower VCE: Ray initialized with resources: {'memory': 53587621479.0, 'node:172.28.0.2': 1.0, 'CPU': 12.0, 'GPU': 1.0, 'object_store_memory': 26793810739.0}\n",
            "INFO flower 2022-10-20 12:41:43,839 | server.py:86 | Initializing global parameters\n",
            "INFO:flower:Initializing global parameters\n",
            "INFO flower 2022-10-20 12:41:43,841 | server.py:266 | Using initial parameters provided by strategy\n",
            "INFO:flower:Using initial parameters provided by strategy\n",
            "INFO flower 2022-10-20 12:41:43,844 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flower:Evaluating initial parameters\n",
            "INFO flower 2022-10-20 12:44:33,491 | server.py:95 | initial parameters (loss, other metrics): tensor(206.2325, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 88.16451962519379}\n",
            "INFO:flower:initial parameters (loss, other metrics): tensor(206.2325, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 88.16451962519379}\n",
            "INFO flower 2022-10-20 12:44:33,497 | server.py:101 | FL starting\n",
            "INFO:flower:FL starting\n",
            "DEBUG flower 2022-10-20 12:44:33,500 | server.py:220 | fit_round 1: strategy sampled 1 clients (out of 10)\n",
            "DEBUG:flower:fit_round 1: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   79.686107\n",
            "1         Cardiomegaly   96.718388\n",
            "2        Consolidation   91.992153\n",
            "3                Edema   96.486535\n",
            "4             Effusion   86.070983\n",
            "5            Emphysema   95.666132\n",
            "6             Fibrosis   73.871946\n",
            "7         Infiltration   78.419832\n",
            "8                 Mass   90.101659\n",
            "9               Nodule   93.062244\n",
            "10  Pleural_Thickening   96.843232\n",
            "11           Pneumonia   72.498662\n",
            "12        Pneumothorax   94.720885\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Created client: 9\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m [Client 9, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Entered train function, total num. of epochs: 5\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 0, loss: 0.9482084653389974\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 100, loss: 0.8389463463245527\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 200, loss: 1.0179940503594536\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 300, loss: 0.8457128192347327\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Epoch : 1 Train Loss : 0.889666 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 0, loss: 0.576011942299962\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 100, loss: 0.8415467734727325\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 200, loss: 0.931160692817264\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 300, loss: 0.781468133933999\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Epoch : 2 Train Loss : 0.849542 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 0, loss: 0.7014303312589905\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 100, loss: 0.8418785222536613\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 200, loss: 0.6725808039055341\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 300, loss: 0.7375110640374641\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Epoch : 3 Train Loss : 0.820356 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 0, loss: 1.1239266245835822\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 100, loss: 0.9606876573223411\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 200, loss: 0.8564195456168004\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 300, loss: 0.8506442829301509\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Epoch : 4 Train Loss : 0.805094 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 0, loss: 0.9472430102791402\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 100, loss: 0.6591187454459294\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 200, loss: 0.7722196155480638\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Iteration 300, loss: 0.6917927327999228\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Epoch : 5 Train Loss : 0.791778 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m Time to complete local training round: 1330.1356880664825\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13727)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-20 13:06:55,625 | server.py:234 | fit_round 1 received 1 results and 0 failures\n",
            "DEBUG:flower:fit_round 1 received 1 results and 0 failures\n",
            "WARNING flower 2022-10-20 13:06:57,048 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flower:No fit_metrics_aggregation_fn provided\n",
            "INFO flower 2022-10-20 13:09:45,547 | server.py:122 | fit progress: (1, tensor(200.0230, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 82.73449397044902}, 1512.0466323359997)\n",
            "INFO:flower:fit progress: (1, tensor(200.0230, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 82.73449397044902}, 1512.0466323359997)\n",
            "DEBUG flower 2022-10-20 13:09:45,552 | server.py:170 | evaluate_round 1: strategy sampled 1 clients (out of 10)\n",
            "DEBUG:flower:evaluate_round 1: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   74.549670\n",
            "1         Cardiomegaly   87.890137\n",
            "2        Consolidation   90.137328\n",
            "3                Edema   75.138220\n",
            "4             Effusion   83.912966\n",
            "5            Emphysema   66.167291\n",
            "6             Fibrosis   95.041912\n",
            "7         Infiltration   79.061887\n",
            "8                 Mass   84.269663\n",
            "9               Nodule   88.764045\n",
            "10  Pleural_Thickening   90.850722\n",
            "11           Pneumonia   77.135723\n",
            "12        Pneumothorax   82.628857\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14147)\u001b[0m Created client: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-20 13:09:54,055 | server.py:184 | evaluate_round 1 received 0 results and 1 failures\n",
            "DEBUG:flower:evaluate_round 1 received 0 results and 1 failures\n",
            "INFO flower 2022-10-20 13:09:54,058 | server.py:144 | FL finished in 1520.5584351079997\n",
            "INFO:flower:FL finished in 1520.5584351079997\n",
            "INFO flower 2022-10-20 13:09:54,066 | app.py:180 | app_fit: losses_distributed []\n",
            "INFO:flower:app_fit: losses_distributed []\n",
            "INFO flower 2022-10-20 13:09:54,069 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO:flower:app_fit: metrics_distributed {}\n",
            "INFO flower 2022-10-20 13:09:54,079 | app.py:182 | app_fit: losses_centralized [(0, tensor(206.2325, device='cuda:0', dtype=torch.float64)), (1, tensor(200.0230, device='cuda:0', dtype=torch.float64))]\n",
            "INFO:flower:app_fit: losses_centralized [(0, tensor(206.2325, device='cuda:0', dtype=torch.float64)), (1, tensor(200.0230, device='cuda:0', dtype=torch.float64))]\n",
            "INFO flower 2022-10-20 13:09:54,081 | app.py:183 | app_fit: metrics_centralized {'mean_class_acc.': [(0, 88.16451962519379), (1, 82.73449397044902)]}\n",
            "INFO:flower:app_fit: metrics_centralized {'mean_class_acc.': [(0, 88.16451962519379), (1, 82.73449397044902)]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14147)\u001b[0m [Client 9] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, centralized):\n",
              "\tround 0: 206.23245081118296\n",
              "\tround 1: 200.02300080857603\n",
              "History (metrics, centralized):\n",
              "{'mean_class_acc.': [(0, 88.16451962519379), (1, 82.73449397044902)]}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "num_rounds = 1\n",
        "local_epochs = 5\n",
        "fraction_fit = 0.1\n",
        "fraction_evaluate = 0.1\n",
        "min_fit_clients = 1\n",
        "min_evaluate_clients = 1\n",
        "\n",
        "client_resources = {\n",
        "    \"num_cpus\": 1,\n",
        "    \"num_gpus\": 1\n",
        "    }\n",
        "\n",
        "def fit_config(server_round: int):    \n",
        "    config = {\n",
        "        \"server_round\": server_round,\n",
        "        \"local_epochs\": local_epochs,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "# Create an instance of the model and get the parameters\n",
        "net = init_net()\n",
        "params = get_parameters(init_net())\n",
        "\n",
        "# Pass parameters to the Strategy for server-side parameter initialization\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=fraction_fit,\n",
        "    fraction_evaluate=fraction_evaluate,\n",
        "    min_fit_clients=min_fit_clients,\n",
        "    min_evaluate_clients=min_evaluate_clients,\n",
        "    min_available_clients=num_clients,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    evaluate_fn=server_eval,\n",
        "    on_fit_config_fn=fit_config,\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=num_clients,\n",
        "    client_resources=client_resources,\n",
        "    config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "    strategy=strategy,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10 local epochs"
      ],
      "metadata": {
        "id": "KePvFqUujud4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhaujrv4UixE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276adb4a-3c79-4dae-b5a6-ceb7b4b07715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flower 2022-10-20 13:22:25,665 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)\n",
            "INFO:flower:Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)\n",
            "INFO flower 2022-10-20 13:22:31,046 | app.py:179 | Flower VCE: Ray initialized with resources: {'CPU': 12.0, 'node:172.28.0.2': 1.0, 'GPU': 1.0, 'memory': 53577036596.0, 'object_store_memory': 26788518297.0}\n",
            "INFO:flower:Flower VCE: Ray initialized with resources: {'CPU': 12.0, 'node:172.28.0.2': 1.0, 'GPU': 1.0, 'memory': 53577036596.0, 'object_store_memory': 26788518297.0}\n",
            "INFO flower 2022-10-20 13:22:31,049 | server.py:86 | Initializing global parameters\n",
            "INFO:flower:Initializing global parameters\n",
            "INFO flower 2022-10-20 13:22:31,052 | server.py:266 | Using initial parameters provided by strategy\n",
            "INFO:flower:Using initial parameters provided by strategy\n",
            "INFO flower 2022-10-20 13:22:31,054 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flower:Evaluating initial parameters\n",
            "INFO flower 2022-10-20 13:25:26,941 | server.py:95 | initial parameters (loss, other metrics): tensor(207.0864, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 84.6496824024914}\n",
            "INFO:flower:initial parameters (loss, other metrics): tensor(207.0864, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 84.6496824024914}\n",
            "INFO flower 2022-10-20 13:25:26,948 | server.py:101 | FL starting\n",
            "INFO:flower:FL starting\n",
            "DEBUG flower 2022-10-20 13:25:26,952 | server.py:220 | fit_round 1: strategy sampled 1 clients (out of 10)\n",
            "DEBUG:flower:fit_round 1: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   89.637953\n",
            "1         Cardiomegaly   95.541288\n",
            "2        Consolidation   70.857856\n",
            "3                Edema   61.655074\n",
            "4             Effusion   86.695202\n",
            "5            Emphysema   94.078830\n",
            "6             Fibrosis   93.115748\n",
            "7         Infiltration   81.273408\n",
            "8                 Mass   76.333155\n",
            "9               Nodule   86.677368\n",
            "10  Pleural_Thickening   95.487783\n",
            "11           Pneumonia   88.050651\n",
            "12        Pneumothorax   81.041555\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Created client: 5\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m [Client 5, round 1] fit, config: {'server_round': 1, 'local_epochs': 10}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Entered train function, total num. of epochs: 10\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.9188192104641673\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.9840345188161964\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 1.132933603131884\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.9347548807273508\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 1 Train Loss : 0.856094 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.7470007609260686\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.7732388911368899\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 0.8384019960630027\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.8261787663024973\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 2 Train Loss : 0.807316 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.649234534342073\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.859691693439245\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 0.7783010468829358\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.8492518921695198\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 3 Train Loss : 0.782631 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.9343971136508373\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.7705664688020099\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 0.794638950621885\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.6866865856746842\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 4 Train Loss : 0.764519 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.6916595706235035\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.8295115957001553\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 0.9773283078851182\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.8140305489325071\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 5 Train Loss : 0.743601 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.7657731150794252\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.7344634653827679\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 0.5673156083269655\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.6032547401190675\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 6 Train Loss : 0.721801 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.7776009531339605\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.6255218872594634\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 0.786070961120461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.7851774914322535\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 7 Train Loss : 0.694749 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.7417431422331846\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.8024939019107953\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 0.720707237115942\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.4868053583168144\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 8 Train Loss : 0.666983 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.5630663960301202\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.512026674600677\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 0.60207278929032\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.5814980327616184\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 9 Train Loss : 0.632988 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 0, loss: 0.6504770247655322\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 100, loss: 0.6483938888789451\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 200, loss: 0.7431990576437828\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Iteration 300, loss: 0.7277162520571746\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Epoch : 10 Train Loss : 0.602048 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m Time to complete local training round: 2713.9030599594116\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14969)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-20 14:10:53,288 | server.py:234 | fit_round 1 received 1 results and 0 failures\n",
            "DEBUG:flower:fit_round 1 received 1 results and 0 failures\n",
            "WARNING flower 2022-10-20 14:10:54,699 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flower:No fit_metrics_aggregation_fn provided\n",
            "INFO flower 2022-10-20 14:13:46,115 | server.py:122 | fit progress: (1, tensor(201.9923, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 92.08132691278759}, 2899.1638341159996)\n",
            "INFO:flower:fit progress: (1, tensor(201.9923, device='cuda:0', dtype=torch.float64), {'mean_class_acc.': 92.08132691278759}, 2899.1638341159996)\n",
            "DEBUG flower 2022-10-20 14:13:46,122 | server.py:170 | evaluate_round 1: strategy sampled 1 clients (out of 10)\n",
            "DEBUG:flower:evaluate_round 1: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Server eval\n",
            "                Labels  Class Acc.\n",
            "0          Atelectasis   89.530943\n",
            "1         Cardiomegaly   97.306938\n",
            "2        Consolidation   88.246834\n",
            "3                Edema   95.077582\n",
            "4             Effusion   87.979312\n",
            "5            Emphysema   94.560371\n",
            "6             Fibrosis   95.238095\n",
            "7         Infiltration   78.972713\n",
            "8                 Mass   94.364188\n",
            "9               Nodule   92.277510\n",
            "10  Pleural_Thickening   96.040663\n",
            "11           Pneumonia   95.238095\n",
            "12        Pneumothorax   92.224006\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15841)\u001b[0m Created client: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-10-20 14:13:54,674 | server.py:184 | evaluate_round 1 received 0 results and 1 failures\n",
            "DEBUG:flower:evaluate_round 1 received 0 results and 1 failures\n",
            "INFO flower 2022-10-20 14:13:54,677 | server.py:144 | FL finished in 2907.725865247001\n",
            "INFO:flower:FL finished in 2907.725865247001\n",
            "INFO flower 2022-10-20 14:13:54,688 | app.py:180 | app_fit: losses_distributed []\n",
            "INFO:flower:app_fit: losses_distributed []\n",
            "INFO flower 2022-10-20 14:13:54,691 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO:flower:app_fit: metrics_distributed {}\n",
            "INFO flower 2022-10-20 14:13:54,700 | app.py:182 | app_fit: losses_centralized [(0, tensor(207.0864, device='cuda:0', dtype=torch.float64)), (1, tensor(201.9923, device='cuda:0', dtype=torch.float64))]\n",
            "INFO:flower:app_fit: losses_centralized [(0, tensor(207.0864, device='cuda:0', dtype=torch.float64)), (1, tensor(201.9923, device='cuda:0', dtype=torch.float64))]\n",
            "INFO flower 2022-10-20 14:13:54,702 | app.py:183 | app_fit: metrics_centralized {'mean_class_acc.': [(0, 84.6496824024914), (1, 92.08132691278759)]}\n",
            "INFO:flower:app_fit: metrics_centralized {'mean_class_acc.': [(0, 84.6496824024914), (1, 92.08132691278759)]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15841)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, centralized):\n",
              "\tround 0: 207.0864017368368\n",
              "\tround 1: 201.99226647068295\n",
              "History (metrics, centralized):\n",
              "{'mean_class_acc.': [(0, 84.6496824024914), (1, 92.08132691278759)]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "num_rounds = 1\n",
        "local_epochs = 10\n",
        "fraction_fit = 0.1\n",
        "fraction_evaluate = 0.1\n",
        "min_fit_clients = 1\n",
        "min_evaluate_clients = 1\n",
        "\n",
        "client_resources = {\n",
        "    \"num_cpus\": 1,\n",
        "    \"num_gpus\": 1\n",
        "    }\n",
        "\n",
        "def fit_config(server_round: int):    \n",
        "    config = {\n",
        "        \"server_round\": server_round,\n",
        "        \"local_epochs\": local_epochs,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "# Create an instance of the model and get the parameters\n",
        "net = init_net()\n",
        "params = get_parameters(init_net())\n",
        "\n",
        "# Pass parameters to the Strategy for server-side parameter initialization\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=fraction_fit,\n",
        "    fraction_evaluate=fraction_evaluate,\n",
        "    min_fit_clients=min_fit_clients,\n",
        "    min_evaluate_clients=min_evaluate_clients,\n",
        "    min_available_clients=num_clients,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    evaluate_fn=server_eval,\n",
        "    on_fit_config_fn=fit_config,\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=num_clients,\n",
        "    client_resources=client_resources,\n",
        "    config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "    strategy=strategy\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPYrM9N9jwej"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "XBYaiOGnS3f9",
        "eScoLyy4_8Ps",
        "KePvFqUujud4"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}